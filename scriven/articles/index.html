<!DOCTYPE html>
<html>
	<head>
		<title>Articles</title>
		<meta charset='utf-8'> 
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		
		<script>var _gaq = _gaq || []; _gaq.push(['_setAccount', 'UA-48616896-1']); _gaq.push(['_setDomainName', 'chrisdadswell.co.uk']); _gaq.push(['_trackPageview']); (function() {var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true; ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js'; var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s); })();</script>
		<!-- useBootstrap -->
	<link href="http://static.smallpicture.com/bootswatch/readable/bootstrap.min.css" rel="stylesheet" />
	<script src="http://static.smallpicture.com/bootstrap/js/jquery-1.9.1.min.js"></script>
	<script src="http://static.smallpicture.com/bootstrap/js/bootstrap.min.js"></script>
	<link rel="stylesheet" href="http://static.smallpicture.com/concord-assets/fontawesome/4.1.0/css/font-awesome.min.css">
		<!-- useSmallPictStyles -->
	<link href="http://fargo.io/cms/platform.css?v=0.48" rel="stylesheet">
	<script src="http://fargo.io/cms/platform.js?v=0.48"></script>
	<script>
		var pagetable = {
    "opmlUrl": "https://dl.dropbox.com/s/ikd20gpzlebbu6i/articles.opml?dl=0",
    "opmlTitle": "Articles",
    "opmlOwnerName": "Chris Dadswell",
    "opmlOwnerEmail": "chrisdadswell@gmail.com",
    "opmlDateModified": "Tue, 13 Jan 2015 21:42:25 GMT",
    "opmlExpansionState": "",
    "opmlLastCursor": "1",
    "opmlOwnerProfile": "scriven.chrisdadswell.co.uk/about.html",
    "opmlLinkPublicUrl": "https://dl.dropbox.com/s/ikd20gpzlebbu6i/articles.opml?dl=0",
    "opmlLink": "",
    "opmlDescription": "This is a blog belonging to the fine and upstanding gentleman known as Christian Dadswell",
    "opmlDateCreated": "",
    "opmlLongTitle": "",
    "opmlOwnerId": "",
    "opmlFeed": "",
    "menuname": "default",
    "googleAnalyticsID": "UA-48616896-1",
    "domain": "chrisdadswell.co.uk",
    "bootstrapTheme": "readable",
    "type": "bloghome",
    "slogan": "Don't slam the door on the way out.",
    "disqusGroupName": "smallpict",
    "siteTimeZone": "0",
    "dateFormat": "%A, %B %e, %Y at %l:%M %p",
    "flIndexPage": false,
    "flDisqusComments": true,
    "flStoryTextOnIndexPage": false,
    "flNonDocHeadsOnIndexPage": true,
    "flStoryDateOnIndexPage": false,
    "storyDateFormat": "%D; %r",
    "maxStoriesOnIndexPage": 25,
    "maxStoryList": 25,
    "authorTwitterAccount": "@chrisdadswell",
    "authorFacebookAccount": "",
    "authorProfileUrl": "scriven.chrisdadswell.co.uk/about.html",
    "titleColor": "red",
    "siteFolder": "blogs/scriven/articles/",
    "flProfile": false,
    "ctLevelsOnIndexPage": 1,
    "blogHomeItemCount": 25,
    "flPgfPermaLinks": false,
    "flFixedMenu": "false",
    "maxStreamDays": "7",
    "flMarkdown": true,
    "leftIndent": 0,
    "text": "Articles",
    "created": "Tue, 13 Jan 2015 21:42:25 GMT",
    "description": "",
    "path": "",
    "subheadColor": "white",
    "flMapHeader": "false",
    "mapLatitude": "40.774295",
    "mapLongitude": "-73.970833",
    "mapType": "roadmap",
    "mapZoom": "14",
    "flSnapEnabled": "true",
    "flHideByline": "false",
    "backgroundImage": "",
    "streamHighlightColor": "yellow",
    "streamTextFrameColor": "whitesmoke",
    "streamVersion": "2",
    "flEmojify": "true",
    "authorGithubAccount": "chrisdadswell",
    "authorLinkedInAccount": "christiandadswell",
    "copyright": "&copy; 2015 Mr C. Dadswell.",
    "menutitle": "Articles",
    "cssUrl": "http://static.smallpicture.com/bootswatch/readable/bootstrap.min.css",
    "menuTitle": "Articles",
    "now": "Tue Jan 13 2015 21:42:26 GMT+0000 (GMT)",
    "url": "/.html"
}; //12/12/13 by DW
		</script>
		<style>
			@media only screen 
			and (min-device-width : 320px) 
			and (max-device-width : 480px) {
				.navbar .nav>li {
					display: none;
					height: 0;
					}
				.divFargoSocialMediaLinks {
					display: none;
					}
				.container {
					margin-top: 10px;
					width: 90%;
					}
				.divFargoMarkdown p {
					font-size: 17px;
					line-height: 140%;
					}
				h2 {
					font-size: 24px;
					line-height: 140%;
					}
				.divHeadlineUnit {
					margin-bottom: 5px;
					}
				.divPrevNext {
					float: none;
					}
				.divBreadcrumbs {
					display: none;
					font-size: 15px;
					}
				.breadcrumb>li>.divider {
					padding: 0;
					padding-left: 1px;
					}
				.spSlogan {
					display: none;
					}
				}
			</style>
		<link href="http://scriven.chrisdadswell.co.uk/css/hover-min.css" rel="stylesheet" media="all">

<style>
	</style>
		<style>
.navbar {
	font-family: 'Ubuntu';
	font-size: 17px;
	border-bottom: cornflowerblue;
	border-bottom-width: thin;
	border-color: aquamarine; 
	border-bottom-style: outset;
	}
.navbar .brand {
	font-family: 'Rancho' !important;
	font-size: 36px !important;
	font-weight: normal !important;
	text-shadow: 0px 0px 6px rgba(150, 150, 150, 0.5);
	}
.navbar .nav {
	text-shadow: 0px 0px 6px rgba(150, 150, 150, 0.5);
	}
.navbar .nav>li {
	text-shadow: 0px 0px 6px rgba(150, 150, 150, 0.5);
	}
.navbar .nav>li>a {
	text-shadow: 0px 0px 6px rgba(150, 150, 150, 0.5);
	}

.navbar .nav li.dropdown.open>.dropdown-toggle {
	background-color: lightsteelblue;
	}
.navbar .nav ul.dropdown-menu {
	background-color: lightsteelblue;
	}


.divStreamDayText {
	font-family: 'Ubuntu';
	font-size: 20px;
	}
.divStreamDayHead {
	font-family: 'Ubuntu', sans-serif;
	font-size: 36px;
	font-weight: bold;
	margin-top: .1em;
	margin-bottom: .60em;
	-webkit-margin-after: .60em;
	}
.aStreamDayLink {
	font-family: 'Ubuntu';
	font-weight: lighter;
	color: rgb(50, 35, 101);
	}
.body {
	font-family: 'Imprima';
	}
.divFargoStreamFooter {
	height: 200px;
	background-color: lightsteelblue;
	}


.divFargoSocialMediaLinks {
	visibility: hidden;
	}


.fa {
	text-shadow: 0px 0px 6px rgba(150, 150, 150, 0.5);
	}
.fa-border {
	padding: .2em .25em .2em; 
	border: solid 0.1em #E7E9F5;
	border-radius: 0.4em; 
	}

</style>
		</head>
	<body>
		<div class="divFargoSocialMediaLinks"><a class="aSocialMediaLink" id="idTwitterLink" href="http://twitter.com/@chrisdadswell" target="_blank"><i class="fa fa-twitter" style="color: #4099FF; font-weight: bold;"></i></a>
<a class="aSocialMediaLink" id="idFacebookLink" href="http://facebook.com/" target="_blank"><i class="fa fa-facebook" style="color: #4C66A4; font-weight: bold;"></i></a>
<a class="aSocialMediaLink" id="idGithubLink" href="http://github.com/chrisdadswell" target="_blank"><i class="fa fa-github" style="color: black; font-weight: bold;"></i></a>
<a class="aSocialMediaLink" id="idLinkedInLink" href="http://www.linkedin.com/in/chrisdadswell" target="_blank"><i class="fa fa-linkedin" style="color: #069; font-weight: bold;"></i></a>
<a class="aSocialMediaLink" id="idRssLink" href="" target="_blank"><i class="fa fa-rss" style="color: orange; font-weight: bold;"></i></a>
</div>
		
<div class="navbar navbar-static-top" id="idFargoNavbar">
	<div class="navbar-inner">
		<div class="navbar-container">
			<a class="brand" href="">Articles</a>
			<ul class="nav">
				<li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Links&nbsp;<b class="caret"></b></a>
					<ul class="dropdown-menu">
						<li><a href="http://www.scripting.com">Scripting News</a></li>
						<li><a href="http://radio3.io/">Radio3</a></li>
						<li><a href="http://littlecardeditor.com">Little Card Editor</a></li>
						<li class="divider"></li>
						<li><a href="http://rivers.chrisdadswell.co.uk" target="_blank"><a href="http://rivers.chrisdadswell.co.uk">River</a></a></li>
						<li><a href="http://radio3.io/users/chrisdadswell" target="_blank"><a href="http://radio3.io/users/chrisdadswell/">Linkblog</a></a></li>
						<li class="divider"></li>
						<li><a href="http://rss.chrisdadswell.co.uk/opml.php?op=publish&key=ivftyv53b090160e7d8">Public OPML Feed</a></li>
						<li><a href="http://littlecardeditor.com/users/chrisdadswell/rss.xml">Little Card Editor Feed</a></li>
						</ul>
					</li>
				<li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Articles&nbsp;<b class="caret"></b></a>
					<ul class="dropdown-menu">
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/contentStructuringForFargoBasedBlog.html">Content Structuring Ideas for a Fargo Based Blog</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/spendingTimeWithDocker.html">Spending time with Docker</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/howToSelfPublishingFargoBlog.html">How-To: Fargo Self-Publishing</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/howtofargoselfpublishingstorageoptions.html">How-To: Fargo Self-Publishing - VPS Storage</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/howToSetupAFargoRiverOfNews.html">How To: Setting up a River of news</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/articles/fargoScripts/">Fargo Scripts</a></li>
						</ul>
					</li>
				<li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Code Snippets&nbsp;<b class="caret"></b></a>
					<ul class="dropdown-menu">
						<li><a href="http://scriven.chrisdadswell.co.uk/codeSnippets/powercliCreatingLocalUsersAndRolesOnEsxi55u2.html" target="_blank"><a href="http://scriven.chrisdadswell.co.uk/codeSnippets/powercliCreatingLocalUsersAndRolesOnEsxi55u2.html">PowerCLI: Creating local users and roles on ESXi 5.5U2</a></a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/codeSnippets/powercliGettingAndSettingRoundRobinPlusIOPSESXi.html">PowerCLI: Getting and Setting Round Robin Pathing Policies on ESXi 5.5</a></li>
						</ul>
					</li>
				<li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Options&nbsp;<b class="caret"></b></a>
					<ul class="dropdown-menu">
						<li><a href="javascript:turnOnImagesCommand ()" target="_blank">Turn images on</a></li>
						<li><a href="javascript:turnOffImagesCommand ();" target="_blank">Turn images off</a></li>
						</ul>
					</li>
				<li class="dropdown"><a href="#" class="dropdown-toggle" data-toggle="dropdown">Archive&nbsp;<b class="caret"></b></a>
					<ul class="dropdown-menu">
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/11">November</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/10">October</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/09">September</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/08">August</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/07">July</a></li>
						<li><a href="http://scriven.chrisdadswell.co.uk/2014/06">June</a></li>
						</ul>
					</li>
				<li><a href="http://scriven.chrisdadswell.co.uk/about.html">About</a></li>
				</ul>
			</div>
		</div>
	</div>

		<div class="divFargoOutlineBody">
			<div id="idOutlineContainer" class="container">
				<div class="divHeadlineUnit" id="idHeadlineUnit" style="display: none;">
					<div class="divBreadcrumbs" id="idBreadcrumbs">
						<ul id="idBreadcrumbList" class="breadcrumb"></ul>
						</div>
					<h2 id="idBlogHomePageTitle">Articles</h2>
					</div>
				<div class="divFargoBlogHome">
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="yourDataVsYourServer.html">Your Data vs. Your Server</a></div>
		<p>After reading Jeffrey Kishner's <a href="http://thoughts.jeffreykishner.com/your-data-vs-your-server">latest post</a> it got me thinking. So rather than put a lengthy comment in his post I thought I'd write my own post in response.</p>

<p>Much like Jeffrey I have used several CMS in the past starting off with Google Sites back in the day (which to my amazement is still going) then moved to Blogger for a short time before ending up on the flavour of the day, back then, WordPress.  </p>

<p>I've sat on Wordpress for a good few years and for the most part it has served its purpose. My www domain for chrisdadswell.co.uk is still on Wordpress but it's days are numbered.</p>

<p>I've dabbled with <a href="http://postach.io">Postach.io</a>, <a href="https://ghost.org/">Ghost</a> and Medium, but they didn't do it for me. In the case of Postach.io I really liked the way it worked, but I dropped using Evernote in favour of Octobox (files are hosted on Dropbox). You can actually self host the Octobox service if you so wish, but I found it flaky! Octobox has nowhere near the functionality of the monolithic Evernote, but it serves my purposes. </p>

<p>Ghost was my first proper foray into self hosting CMS, but didn't like the fact it was all lumped into a database. </p>

<p>And Medium hasn't got a self hosting option, but it looks nice so tried it out and eventually dropped it (where are the RSS feeds?)</p>

<p>I came to my current CMS, <a href="http://fargo.io">Fargo.io</a> about two years ago and haven't really looked back since. This blog is authored at Fargo.io. And I self host the publisher and static pages. It suits my needs exactly. The only downside for me is the VPS provider*.</p>

<p>As it stands I run several services on my VPS(s) including this blog (and fargoPublisher), <a href="http://rivers.chrisdadswell.co.uk">Rivers</a>, TTRSS and soon tweetToRSS. As for the data consumed by them, all of it is held on Dropbox.</p>

<p>If the VPS(s) go down, which they do, I don't currently have a mechanism to resurrect all my services elsewhere, but I'm chipping away at that in various ways.</p>

<p>In the case of my blog I have started syncing my static content to my Github Pages site. With the switch of a DNS name I should be able to get my blog back and available in no time. I wouldn't be able to publish any new content until my fargoPublisher was back but that's not earth shattering. </p>

<p>Self hosting Node applications such as River, fargoPublisher, tweetToRss has a major downside when the VPS go away and currently I am at the mercy of CloudAtCost to get my servers back for me... when they feel like it. Not great, but welcome to "on the cheap" cloud computing. If I wanted SLA's and better support I know I could go elsewhere, but I'm currently comfortable accepting what they offer.</p>

<p>Ultimately, I still have the data available from Dropbox that is sync'd with my home PC. I can control my *.chrisdadswell.co.uk domain using Cloudflare and push comes to shove I can just buy more cloud compute and get those services back up in a jiffy. </p>

<p>In a nutshell when I see new services coming along my first question is always "how much of this thing can I self host?"</p>

<p>The closer I can get to the application and data being completely self hosted the better.</p>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">01/13/15; 07:39:50 PM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="yourDataVsYourServer.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="contentStructuringForFargoBasedBlog.html">Content Structuring Ideas for a Fargo Based Blog</a></div>
		<p><a href="https://twitter.com/share?text=Content%20Structuring%20Ideas%20for%20a%20Fargo%20Based%20Blog&amp;url=undefined" target="_blank">Tweet This Post</a></p>

<p><a href="http://radio3.io/?title=Content%20Structuring%20Ideas%20for%20a%20Fargo%20Based%20Blog&amp;link=undefined&amp;description=Content%20Structuring%20Ideas%20for%20a%20Fargo%20Based%20Blog" target="_blank">Share article with Radio3</a></p>

<p>I use Fargo as my blogging CMS almost daily and really enjoy the flexibility it affords me. Of late though I had been noticing some serious lag when editing my main Scriven blog. I use Fargo.io 80% of the time on my Chromebook and it was getting close to unusable so I decided to perform some jiggery pockery to get things optimised.</p>

<p>Before I get onto the symptoms and remedial actions, here is the setup of this blog;</p>

<ul>
<li><p>Fargo publisher is self hosted - The publisher that produces the static files from Fargo.io</p></li>
<li><p>I use <code>#type="stream"</code> style blog</p></li>
<li><p>I use #siteFolder directive to publish the static content into Dropbox/Apps/Fargo/blogs/scriven. The directive looks like this <code>#siteFolder="/blogs/scriven/"</code> within my <a href="https://dl.dropbox.com/s/77dh8j4y3ql7zbe/scriven.opml">scriven.opml</a>.</p></li>
<li><p>The blog content is self hosted - The static pages are kept in sync with Dropbox and my web server.</p></li>
</ul>

<p><b>Symptoms</b></p>

<ul>
<li><p>The lag, for the most part, was most notable at page refreshes, when selecting a bar of text and entering new words into it and then whilst 'Save' process kicked in. This was freezing the interface for 3-4 seconds at a time. </p></li>
<li><p>Another area of lag occurred when expanding outlines. The larger the outline the worse the lag,.</p></li>
<li><p>I also found that if a large outline was expanded and I needed to jump up the page this would also cause a freeze in the interface.</p></li>
</ul>

<p><b>Cause</b></p>

<ul>
<li><p>I believe the cause of the lag is down to the active and open opml, in this instance Scriven.opml had too many entries in it. I'm assuming that this opml is opened and held in memory whilst it is being edited. I'd also assume that any opmls that are opened into Fargo are also held in memory. Watching the Chrome task manager doesn't seem to give much away when opening and closing opml files.</p></li>
<li><p>On machines with lowish memory, such as my 2gb Chromebook you can appreciate RAM is at a premium!</p></li>
<li><p>So in order to reduce the lag and up the performance one must reduce the amount of text, or large outlines in the opml.</p></li>
<li><p>Fortunately, I had a plan...</p></li>
</ul>

<p><b>Blog Structure</b></p>

<ul>
<li><p>Initially I started off by picking the low hanging fruit and archived previous calendar months worth of posts using menu option File | Archive cursor. This didn't seem to have much impact, but then the posts were never that large anyway. Mainly short titles and then a link to an article. </p></li>
<li><p>So the next issue was how to break out the articles and other lengthy posts from what I'll call my blog "shop face" i.e., the day to day short posts.</p></li>
<li><p>Fortunately I'd already broken down the structure of my blog so that the day to day posts didn't include the content of an article.  </p></li>
<li><p>All articles lived in a separate part of scriven.opml away from the day-to-day posts. To elaborate, I had a parent "Articles" entry with it's attribute set to "type | blogHome". I then created sub entries as the articles themselves as "type | outline". For example;</p></li>
<li><p>Articles &lt;- type | blogHome</p>

<ul><li><p>Some article I hope someone may want to read &lt;- type | outline</p></li>
<li><p>Another long article talking about this and that &lt;- type | outline</p></li></ul></li>
<li><p>When the blog was rendered, the 'Articles' entry gets created as a folder and the sub entries as article content. i.e., http://blogURL/articles/someArticleIHopeSomeoneMayWantToRead.html</p></li>
<li><p>I continued to use this method when I wanted to create articles under different categories. Such as my code snippets and virtualisation posts.</p></li>
</ul>

<p><b>Next steps</b></p>

<ul>
<li><p>So to split the articles from the shop face I decided to create a new <a href="https://dl.dropbox.com/s/ikd20gpzlebbu6i/articles.opml">articles.opml</a> file within Fargo and copy all the articles, including the parent to the new file. </p></li>
<li><p>So it looked like;</p>

<ul><li><p>Articles &lt;- type | blogHome</p></li>
<li><p>Some article I hope someone may want to read &lt;- type | outline</p></li>
<li><p>Another long article talking about this and that &lt;- type | outline</p></li></ul></li>
<li><p>I also copied over the #siteFolder directive.</p></li>
<li><p>When I first rendered the content again it has some undesirable effects. Firstly it rendered all the content to the correct folder, /articles, but the index.html that was rendered for /articles/index.hml was rendered also rendered into /scriven/index.html.</p></li>
<li><p>After a couple of minutes head scratching I realised my error. My #siteFolder was set /blog/scriven/</p></li>
<li><p>So I corrected this to /blog/scriven/articles/ and rendered all the articles again. This time it rendered to path /blogs/scriven/articlesarticles/</p></li>
<li><p>More head scratching and then :lightbulb:. I realised I didn't need a parent "Articles", I could just lump all the articles at the root! Re-rendered all content and it created the files correctly within /blog/scriven/articles/ and didn't overwrite the /blogs/scriven/index.html <img title=':thumbsup:' alt=':thumbsup:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/thumbsup.png' align='absmiddle' /></p></li>
<li><p>The only other entry in the articles.opml file was the #menus directive that contains my blog menus. </p></li>
<li><p>On the subject of menus, I really want a way to have my menus in cmsPrefs.opml and have different menu titles per opml. If anyone knows how to do this, let me know.</p></li>
<li><p>I repeated the above for my virtualisation and code snippets categories.</p></li>
</ul>

<p><b>Results</b></p>

<ul>
<li><p>With scriven.opml now containing only day-to-day posts and a few other directives the performance increase was immediate.  </p></li>
<li><p>Load times are now quicker and there is no lag whatsoever when editing.</p></li>
<li><p>So you might be thinking, "well, you've just moved the lag to another opml!". Well no, that hasn't been the case. I am able to edit, expand and collapse with no noticeable lag in any of the open outlines!</p></li>
</ul>

<p>I sincerely <img title=':heart:' alt=':heart:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/heart.png' align='absmiddle' /> using Fargo and the way in which I can control exactly how <b><i>I</i></b> want things to work and <i><b>where</b></i> the content is hosted. Totally under my control! </p>

<p>Looking forward, I can't wait to see what Dave is doing over at <a href="http://scripting.com/2014/10/20/newScriptingNewsHomePageComing.html">Scripting.com</a> in the near future. The tie up with all his recent efforts should be something pretty special.</p>

<p>Exciting times.</p>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">10/19/14; 06:47:46 PM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="contentStructuringForFargoBasedBlog.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="spendingTimeWithDocker.html">Spending some time with Docker</a></div>
		<p><a href="http://radio3.io/?title=Spending%20some%20time%20with%20Docker&amp;link=http://scriven.chrisdadswell.co.uk/articles/spendingTimeWithDocker&amp;description=Spending%20some%20time%20with%20Docker" target="_blank">Share article with Radio3</a></p>

<p><a href="https://twitter.com/share?text=Spending%20some%20time%20with%20Docker&amp;url=http://scriven.chrisdadswell.co.uk/articles/spendingTimeWithDocker" target="_blank">Tweet This Post</a></p>

<p><b>Introduction</b></p>

<ul>
<li><p>I'd been meaning to have an R &amp; D session with Docker for some time so decided to jump in and have a play.</p></li>
<li><p>There is plenty of support and content on the internet to explain what <a href="https://www.docker.com/whatisdocker/">Docker is about</a> so I won't be detailing that here. I just wanted to record the experience of picking it up for the first time and seeing what was possible after a few days of tinkering.</p></li>
</ul>

<p><b>What did I set out to do?</b></p>

<ul>
<li>I tend to pick things up best when I have some outcome I am aiming for. My aim for the week was to get a dockerized <a href="https://github.com/scripting/river4/blob/master/README.md">River4</a> (using local file storage) with a web server (to serve the Rivers) up and running. I started out by just getting the River4 aggregator up and running in a Docker container. A container is like an 'image' of software that supports the running of an application. In this instance it is an image which holds the software required to support the running of NodeJS.</li>
</ul>

<p><b>Disclaimer</b></p>

<ul>
<li>My intention was to get River4 and a web server dockerized and I achieved this, but for some reason I haven't yet worked out, River4 processes feeds but I cannot see the output. I'm sure I'll work it out, but the point of the exercise was to learn about Docker and try to get applications running in Docker and interacting with each other. I'm sure there are better ways to achieve what I ended up doing, but it's all a learning experience.</li>
</ul>

<p><b>So where to start?!</b></p>

<ul>
<li><p>Well first off you need a server to run Docker on. I had a development Ubuntu VPS on which to install Docker. I just used the <a href="http://docs.docker.com/installation/ubuntulinux/">install manual</a> from the Docker site. Real easy install.</p></li>
<li><p>Next up, an Docker image that supports NodeJS. This is where the <a href="https://registry.hub.docker.com/">Docker hub registry</a> comes in. Its a place where you can search and download Docker images for specific use cases. I decided to use the <a href="https://registry.hub.docker.com/u/google/nodejs/">Google NodeJS image</a>.</p></li>
<li><p>So once Docker is <a href="http://docs.docker.com/installation/ubuntulinux/">installed</a> you can pull down your first image from the hub.</p></li>
</ul>

<p><b>Pulling images</b></p>

<ul>
<li><p>To pull an image is simples - <code>docker pull google/nodejs:latest</code></p></li>
<li><p>I use the '<i>:latest</i>' to pull only the most recent version. If you don't use '<i>:latest</i>' it will pull all versions of this image down. The google/nodejs image is about 350mb so you don't want too many versions of that floating about! Although you can easily delete images. More on that later. </p></li>
<li><p>To search for available images at the command line - <code>docker search nodejs</code></p></li>
<li><p>Once you start to pull an image it will take a little time to download everything required.</p></li>
</ul>

<p><b>Viewing images</b></p>

<ul>
<li><p>To see what images you have available - <code>docker images</code></p></li>
<li><p>This will list all the images you currently have stored and their ID/versions and tags. Tags are really useful ways of storing an image at a memorable point/version.</p></li>
</ul>

<p><b>Removing images</b></p>

<ul>
<li><p>To delete an image, first off you need to list them to get back the container ID - <code>docker images</code></p></li>
<li><p>Then - <code>docker rmi <ID></code></p></li>
<li><p>It's worth noting you only need enter the first three numbers of the ID. If an image is currently running (more on this later) you <b>cannot</b> delete the image. It will warn you that the image is in use.</p></li>
</ul>

<p><b>Creating a River4 Docker container</b></p>

<ul>
<li><p>A Docker <a href="https://docs.docker.com/terms/container/">container</a> is everything in the image plus the unique ID, networking configuration and resource limits. Containers can be running or exited.</p></li>
<li><p>River4 is a NodeJS RSS aggregator that is able to utilize either Amazon S3 or local file storage as its means to store files. I will be using River4 with local fs (fspath) option.</p></li>
<li><p>Running a River4 is a very easy task;</p>

<ul><li><ol><li>An OS that supports NodeJS is required</li></ol></li>
<li><ol><li>Git clone https://github.com/scripting/river4.git</li></ol></li>
<li><ol><li>Export a variable - fspath=/rivers/ &lt;- This points to the area on disk that holds the River4 static data</li></ol></li>
<li><ol><li>Run the River4 - node /river4/river4.js</li></ol></li></ul></li>
<li><p>Now we need to replicate this setup within a Docker image.</p></li>
<li><p>Docker allows for automated builds by way of the 'Dockerfile'. Contents within Dockerfile allow for automated image builds.</p></li>
<li><p>Dockerfiles are then built step by step using the <code>docker build</code> command.</p></li>
<li><p>The syntax used within this file is pretty straight forward and well <a href="https://docs.docker.com/reference/builder/">documented</a>. To start playing around with this I created a directory called /riverdocker and created the Dockerfile.</p></li>
<li></li>
<li><p>River4fs Dockerfile</p>

<ul><li># Dockerized version of River4 using local filesystem</li>
<li># DOCKER-VERSION 1.2.0</li>
<li><p>FROM    google/nodejs:latest</p></li>
<li><p>MAINTAINER      Christian Dadswell "chrisdadswell@gmail.com"</p></li>
<li><p>RUN     git clone https://github.com/scripting/river4.git; cd river4; npm install; mkdir -p rivers/lists</p></li>
<li><p>ADD     https://dl.dropbox.com/s/0nglcm35uhpxpqx/rivers.opml /rivers/lists/</p></li>
<li><p>EXPOSE  1337</p></li>
<li><p>WORKDIR /rivers</p></li>
<li><p>ENTRYPOINT ["node", "/river4/river4.js"]</p></li></ul></li>
<li></li>
<li><p>The hashed out lines are just comments</p></li>
<li><p><code><a href="https://docs.docker.com/reference/builder/#from">FROM</a> google/nodejs:latest</code> line denotes which image we will be using for the container</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#maintainer">MAINTAINER</a></code> line is pretty self explanatory, but ensures that if the image is pushed (<code>docker push</code>) to the Docker Repo Hub people using the image will know who to contact with issues.</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#run">RUN</a>     git clone https://github.com/scripting/river4.git; cd river4; npm install; mkdir -p rivers/lists</code> line clones the river4 code into /river4, changes directory to it and installs uses npm to install the required modules and finally creates a lists folder in the /rivers directory to later store opml files that are read by the River4 aggregator.</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#add">ADD</a>     https://dl.dropbox.com/s/0nglcm35uhpxpqx/rivers.opml /rivers/lists/</code> line downloads an opml file from Dropbox. This file contains all my RSS subscriptions.</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#expose">EXPOSE</a> 1337</code> line tells the container to listen on the specified port at runtime. River4 dashboard requires this port.</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#workdir">WORKDIR</a> /rivers</code> line sets the working directory for RUN, COMMAND and ENTRYPOINT instructions</p></li>
<li><p>The <code><a href="https://docs.docker.com/reference/builder/#entrypoint">ENTRYPOINT</a> ["node", "/river4/river4.js"]</code> line  configures the container to run as an executable.  </p></li>
</ul>

<p><b>Building images</b></p>

<ul>
<li><p>So with the Dockerfile complete it's time to build the image.  Here is the command that is run from the directory containing the Dockerfile;</p></li>
<li><p><code>docker build --rm=true -t chrisdadswell/river4fs .</code> </p></li>
<li><p><code>docker build</code>  is the main command, <code>--rm=true</code> deletes any intermediate containers, <code>-t chrisdadswell/river4fs .</code> the <code>-t</code> tells the builder to create a repository name of <code>chrisdadswell/river4fs</code> and the final <code>.</code> tells the build where to read the Dockerfile from.</p></li>
<li><p>The image is built from this command and will take a few moments. Once finished can be seen by entering <code>docker images</code></p></li>
</ul>

<p><b>Executing commands in a container</b></p>

<ul>
<li><p>Now it is time to execute the River4 aggregator.</p></li>
<li><p><code>docker run -d -p 1337:1337 -e fspath=/rivers/ -t -i chrisdadswell/river4fs</code> </p></li>
<li><p><code>docker run</code> is the main command, <code>-d</code> daemonizes the process, <code>-p 1337:1337</code> publishes the containers port to the host, the <code>-e fspath=/rivers/</code> sets the environment variable <code>-t -i chrisdadswell/river4fs</code> allocates a terminal and makes the container interactive.</p></li>
<li><p>Executing this command generates a long container ID.</p></li>
</ul>

<p><b>Viewing the results</b></p>

<ul>
<li><p>River4 will now be running as a Docker process. To see the process enter <code>docker ps</code></p></li>
<li><p>The output looks like this;</p></li>
<li><p><code>a203e2e8cd00        chrisdadswell/river4fs:latest    "node /river4/river4   4 seconds ago       Up 3 seconds        0.0.0.0:1337->1337/tcp   mad_kirch</code> </p></li>
<li><p>Not much to look at in and of itself, but we need the container ID in order to see what is going on inside the container.</p></li>
<li><p>To take a look at what is actually happening we can use the following command, <code>docker logs -f containerID</code>. Remember you only need the first three numbers.</p></li>
<li><p>The output will look similar to this;</p>

<ul><li><p><pre></p></li>
<li><p>River4 v0.96 running on port 1337.</p></li>
<li><p>Running from the filesystem: /rivers/</p></li>
<li><p>loadServerData: /rivers/data/prefsAndStats.json</p></li>
<li><p>loadServerData: error == ENOENT, open '/rivers/data/prefsAndStats.json'</p></li>
<li><p>loadTodaysRiver: /rivers/data/calendar/2014/10/04.json</p></li>
<li><p>readOneList: listname == rivers.opml, filepath == /rivers/lists/rivers.opml</p></li>
<li><p>copyIndexFile: /rivers/index.html</p></li>
<li><p>readFeed: urlfeed == http://test.chrisdadswell.co.uk/rss.xml</p></li>
<li><p>everyMinute: 21:03:03, 0 items on the task queue, 0 sockets open, 1 feeds in the struct.</p></li>
<li><p>saveFeedsArray: /rivers/data/feedsStats.json</p></li>
<li><p>readOneList: listname == rivers.opml, filepath == /rivers/lists/rivers.opml</p></li>
<li><p></pre></p></li></ul></li>
<li><p>The River4 application is running in a Docker container and processing feeds.</p></li>
<li><p>To further <a href="http://docs.docker.com/reference/commandline/cli/#inspect">inspect</a> the container we can use <code>docker inspect containerID</code>. This returns a lot of information about the container. This is useful for troubleshooting settings and for seeing what a container logically looks like.</p></li>
<li><p>The final stage of this is to look at the River4 dashboard.  Head to http://rivers.yourdomain.co.uk:1337/dashboard to see the result.</p></li>
<li><p>So next up I needed a web server to serve up the river content. This brings up an interesting scenario where you need the web server container to serve content from the River4 container.</p></li>
</ul>

<p><b>Creating a basic web server container</b></p>

<ul>
<li><p>Having used the npm http-server module before I chose to use it again and make a container.</p></li>
<li></li>
<li><p>River4web Dockerfile</p>

<ul><li># Docker Web Server</li>
<li># DOCKER-VERSION 1.2.0</li>
<li><p>FROM    google/nodejs:latest</p></li>
<li><p>MAINTAINER      Christian Dadswell "chrisdadswell@gmail.com"</p></li>
<li><p>RUN     npm install http-server -g</p></li>
<li><p>EXPOSE  80</p></li>
<li><p>ENTRYPOINT ["http-server", "/rivers", "-p", "80", "-d", "false", "-a", "0.0.0.0"]</p></li></ul></li>
<li></li>
<li><p>Pretty self explanatory what is going on here, but the main point of interest is with the <a href="https://docs.docker.com/reference/builder/#entrypoint">ENTRYPOINT</a> line and the <code>/rivers</code>. This is telling the http-server the directory to which it is to serve content.</p></li>
<li><p>If we were to execute this container it would have no content to serve up. That is because there is nothing in <code>/rivers</code> to serve. Even if I run both the River4 and Web containers together the web server will still not show any content. This is because both are running in isolation of each other.</p></li>
<li><p>In any case, here is the command to execute this container - <code>docker run -d -p 80:80 -t -i chrisdadswell/river4web</code> </p></li>
<li><p>The next step is therefore to allow the web server container to see the content of the River4 <code>/rivers</code> container.</p></li>
</ul>

<p><b>How to make the containers interact</b></p>

<ul>
<li><p>This area of configuration was the most interesting part for me. How to make two independent containers interact and 'share'  data storage. Fortunately, Docker has this sown up! But it does require a bit of thought. I'll try my best here to explain how I got this working.</p></li>
<li><p>Remember that by default containers are totally isolated unless you link them in some way. </p></li>
<li><p>Docker allows the creation of links between one to many containers by way of the <code>--link</code>. This is a route I investigated and tried, but it didn't fit my needs. You can read about the use of --link from the links at the end of the article. </p></li>
<li><p>The route I chose was to use the <code>--volumes-from</code> run time flag when launching the web server container. This flag allows you to connect a container to the volume of another container by way of passing it the containerID of the River4 container. If you remember, the River4 container exposes a volume called <code>/rivers</code>. We will attach the web server container to this read write volume.</p></li>
<li><p>To start both containers and pass the containerID to the web server is pretty straightforward and so I created a bash script to do it.</p></li>
<li><p><!-- outlineEmbedCode -- this version gets you a reader -->
	<script src="http://fargo.io/code/concord.js" /></script>
	<script src="http://fargo.io/code/utils.js"></script>
	<style>
		.divTrexEmbeddedOutlineContainer {
			margin-bottom: 20px;
			}
		.divTrexEmbeddedOutlineContainer .divTrexEmbeddedOutliner {
			min-height: 10em;
			max-height: 30em;
			border:1px solid gainsboro;
			border-top-width: 0;
			border-bottom-width: 0;
			overflow-y: auto;
			background-color: white;
			padding: 6px;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divInfoRight {
			float: right;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divOutlineTitle {
			font-weight: bold;
			}
		</style>
	<div class="divTrexEmbeddedOutlineContainer">
		<div id="idAboveOutlineInfo" class="divAboveOutlineInfo">
			<div id="idViewSource" class="divInfoRight"></div>
			<div id="idOutlineTitle" class="divInfoLeft divOutlineTitle"></div>
			</div>
		<div id="idTrexEmbeddedOutliner" class="divTrexEmbeddedOutliner"></div>
		<div id="idBelowOutlineInfo" class="divBelowOutlineInfo">
			<div class="divInfoRight">
				<i class="fa fa-heart" style="color: red; opacity: 0.6; font-size: 0.9em;"></i> 
				<a href="http://fargo.io/" target="_blank">Fargo</a>
				</div>
			<div class="divInfoLeft"></div>
			</div>
		</div>
	<script>
		var font = "Arial", fontSize = 16, lineHeight = 24;
		var opmlUrl = "https://dl.dropboxusercontent.com/s/9ousyrfiq3pydyk/d8b54c49c035403e141d4c466318df31.opml?dl=0";
		function opKeystrokeCallback () {
			}
		function setPrefs () {
			$("#idTrexEmbeddedOutliner").concord ({
				"prefs": {
					"outlineFont": font, 
					"outlineFontSize": fontSize, 
					"outlineLineHeight": lineHeight,
					"renderMode": true,
					"readonly": true,
					"typeIcons": appTypeIcons
					},
				"callbacks": {
					"opExpand": opExpandCallback,
					"opKeystroke": opKeystrokeCallback
					}
				});
			}
		function getOutline (opmlUrl) {
			var jxhr = $.ajax ({
				url: opmlUrl,
				dataType: "text",
				timeout: 30000
				})
			.success (function (data, status, xhr) {
				if (xhr.status==200) {
					var title;
					$("#idTrexEmbeddedOutliner").concord ().op.xmlToOutline (data, false);
					title = $("#idTrexEmbeddedOutliner").concord ().op.getTitle ();
					$("#idOutlineTitle").html (title);
					$("#idViewSource").html ("<a href='" + opmlUrl + "'>view  source</a>");
					}
				})
			.error (function (status, textStatus, errorThrown) {
				console.log ("checkOutline: error == " + errorThrown + ", status == " + textStatus);
				});
			}
		$(document).ready (function () {
			setPrefs ();
			getOutline (opmlUrl);
			});
		</script></p></li>
<li><p>Note the <code>--volumes-from $river4</code>. This is the bit where the web server is being attached to the volume of the River4 container.</p></li>
<li><p>When we run this script we can inspect the linked volume by running <code>docker inspect containerID</code></p></li>
<li><p>First we need to get the containerID's for both containers.</p></li>
<li><p><code>docker process</code>, then docker inspect containerID against both containerIDs.</p></li>
<li><p>The end of the output for the river4fs and river4web containers looks like the following;</p></li>
<li><p><!-- outlineEmbedCode -- this version gets you a reader -->
	<script src="http://fargo.io/code/concord.js" /></script>
	<script src="http://fargo.io/code/utils.js"></script>
	<style>
		.divTrexEmbeddedOutlineContainer {
			margin-bottom: 20px;
			}
		.divTrexEmbeddedOutlineContainer .divTrexEmbeddedOutliner {
			min-height: 10em;
			max-height: 30em;
			border:1px solid gainsboro;
			border-top-width: 0;
			border-bottom-width: 0;
			overflow-y: auto;
			background-color: white;
			padding: 6px;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divInfoRight {
			float: right;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divOutlineTitle {
			font-weight: bold;
			}
		</style>
	<div class="divTrexEmbeddedOutlineContainer">
		<div id="idAboveOutlineInfo" class="divAboveOutlineInfo">
			<div id="idViewSource" class="divInfoRight"></div>
			<div id="idOutlineTitle" class="divInfoLeft divOutlineTitle"></div>
			</div>
		<div id="idTrexEmbeddedOutliner" class="divTrexEmbeddedOutliner"></div>
		<div id="idBelowOutlineInfo" class="divBelowOutlineInfo">
			<div class="divInfoRight">
				<i class="fa fa-heart" style="color: red; opacity: 0.6; font-size: 0.9em;"></i> 
				<a href="http://fargo.io/" target="_blank">Fargo</a>
				</div>
			<div class="divInfoLeft"></div>
			</div>
		</div>
	<script>
		var font = "Arial", fontSize = 16, lineHeight = 24;
		var opmlUrl = "https://dl.dropboxusercontent.com/s/457jat079k2wl52/146995ba8d67a58fef08a7f061c73384.opml?dl=0";
		function opKeystrokeCallback () {
			}
		function setPrefs () {
			$("#idTrexEmbeddedOutliner").concord ({
				"prefs": {
					"outlineFont": font, 
					"outlineFontSize": fontSize, 
					"outlineLineHeight": lineHeight,
					"renderMode": true,
					"readonly": true,
					"typeIcons": appTypeIcons
					},
				"callbacks": {
					"opExpand": opExpandCallback,
					"opKeystroke": opKeystrokeCallback
					}
				});
			}
		function getOutline (opmlUrl) {
			var jxhr = $.ajax ({
				url: opmlUrl,
				dataType: "text",
				timeout: 30000
				})
			.success (function (data, status, xhr) {
				if (xhr.status==200) {
					var title;
					$("#idTrexEmbeddedOutliner").concord ().op.xmlToOutline (data, false);
					title = $("#idTrexEmbeddedOutliner").concord ().op.getTitle ();
					$("#idOutlineTitle").html (title);
					$("#idViewSource").html ("<a href='" + opmlUrl + "'>view  source</a>");
					}
				})
			.error (function (status, textStatus, errorThrown) {
				console.log ("checkOutline: error == " + errorThrown + ", status == " + textStatus);
				});
			}
		$(document).ready (function () {
			setPrefs ();
			getOutline (opmlUrl);
			});
		</script></p></li>
<li><p>Note that both containers are using the same /rivers path on the <a href="https://docs.docker.com/terms/layer/">aufs</a>. You can <code>ls -l</code> this path to see the contents.</p>

<ul><li><p><pre></p></li>
<li><p>total 36</p></li>
<li><p>drwxr-xr-x 4 root root  4096 Oct  8 15:47 data</p></li>
<li><p>-rw-r--r-- 1 root root 23956 Oct  8 15:42 index.html</p></li>
<li><p>drwxr-xr-x 2 root root  4096 Oct  5 17:02 lists</p></li>
<li><p>drwxr-xr-x 2 root root  4096 Oct  8 15:47 rivers</p></li>
<li><p></pre></p></li></ul></li>
<li><p>As you can see content is being generated by river4fs container and is available to the river4web container.</p></li>
</ul>

<p><b>View the results</b></p>

<ul>
<li><p>So now its time to view the results of the work carried out. In my setup I have an 'A' record which points to the fixed IP address of my Ubuntu VPS. e.g., rivers.chrisdadswell.co.uk IN A 123.123.123.123.</p></li>
<li><p>To view the River4 dashboard go to - http://<your_river_domain>:1337/dashboard</p></li>
<li><p>To view the River4 output go to - http://<your_river_domain></p></li>
</ul>

<p>My next steps are to get River4 working 100% and possibly as one image. I'll then create a Docker repo hub on another VPS to store my images. This is because Docker Hub Registry only allows 1 private repository.</p>

<p><b>Useful Docker aliases - Saves on the typing!</b></p>

<ul>
<li><p>Here are some aliases I've setup in my ~/.profile</p></li>
<li><p>alias dim='docker images'</p></li>
<li><p>alias dps='docker ps'</p></li>
<li><p>alias rmc='docker rm $(sudo docker ps -a -q)'</p></li>
<li><p>alias dlogs='docker logs -f $i'</p></li>
<li><p>alias dins='docker inspect $i'</p></li>
</ul>

<p><b>Useful Docker links</b></p>

<ul>
<li><p><a href="https://docs.docker.com/reference/builder/">https://docs.docker.com/reference/builder/</a></p></li>
<li><p><a href="https://docs.docker.com/userguide/dockerhub/">https://docs.docker.com/userguide/dockerhub/</a></p></li>
<li><p><a href="http://docs.docker.com/userguide/dockervolumes/">http://docs.docker.com/userguide/dockervolumes/</a></p></li>
<li><p><a href="http://docs.docker.com/installation/ubuntulinux/">http://docs.docker.com/installation/ubuntulinux/</a></p></li>
<li><p><a href="https://registry.hub.docker.com/u/google/nodejs/">https://registry.hub.docker.com/u/google/nodejs/</a></p></li>
<li><p><a href="https://docs.docker.com/userguide/dockerlinks/">https://docs.docker.com/userguide/dockerlinks/</a></p></li>
<li><p><a href="https://crosbymichael.com/advanced-docker-volumes.html">https://crosbymichael.com/advanced-docker-volumes.html</a></p></li>
<li><p><a href="http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html">http://www.offermann.us/2013/12/tiny-docker-pieces-loosely-joined.html</a></p></li>
<li><p><a href="http://www.dockerbook.com/">http://www.dockerbook.com/</a></p></li>
</ul>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">10/01/14; 02:34:08 PM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="spendingTimeWithDocker.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="deployingARiverAMIFromEc2.html">Deploying a River from an Amazon EC2 AMI</a></div>
		<p><b>Introduction</b></p>

<ul>
<li><p>In this very short article I will show you how straight forward it will be to launch a River instance from EC2 without the need for any command line operations.</p></li>
<li></li>
<li><p>NOTE: The River-AMI is not yet available on the AWS Marketplace.</p></li>
</ul>

<p><b>Pre-requisites</b></p>

<ul>
<li><p>An Amazon AWS account (free for 12 months*) </p></li>
<li><p>A domain name you own</p></li>
<li><p>A copy of your AWS Access and Secret keys</p></li>
<li><p>An Amazon S3 bucket for your Rivers with a bucket policy set</p>

<ul><li><p>Log into AWS and select S3</p></li>
<li><p>Create Folder and enter rivers.mydomain.co.uk - obviously substitute your domain with the example above</p></li>
<li><p>Select Properties at the top right to view the properties of the new folder</p></li>
<li><p>Select Static Website Hosting</p></li>
<li><p>Take a copy of the Endpoint: URL</p></li>
<li><p>Select Enable website hosting</p></li>
<li><p>Save</p></li>
<li><p>Creating S3 bucket policy</p></li>
<li><p>Select Permissions just above the Static Website Hosting</p></li>
<li><p>Select Edit bucket policy</p></li>
<li><p>Copy and paste the following - substituting your River address i.e., rivers.mydomain.co.uk</p></li>
<li><p><code></p></li>
<li><p>{</p></li>
<li><p>"Version": "2012-10-17",</p></li>
<li><p>"Statement": [</p>

<ul><li><p>{</p></li>
<li><p>"Sid": "AddPerm",</p></li>
<li><p>"Effect": "Allow",</p></li>
<li><p>"Principal": {</p></li>
<li><p>"AWS": "*"</p></li>
<li><p>},</p></li>
<li><p>"Action": "s3:GetObject",</p></li>
<li><p>"Resource": "arn:aws:s3:::<YOUR_RIVER_ADDRESS>/*"</p></li>
<li><p>}</p></li></ul></li>
<li><p>]</p></li>
<li><p>}</p></li>
<li><p></code></p></li>
<li><p>Click Save</p></li></ul></li>
<li><p>Create a CNAME record that points to the S3 bucket endpoint URL</p>

<ul><li><p>Within your DNS configuration console create  a new CNAME record that points to the S3 endpoint URL recorded above</p></li>
<li><p><img src="https://dl.dropbox.com/s/6vun0p2tyuts3nz/CNAME.png?dl=0" &lt;="" img=""></p></li></ul></li>
<li></li>
<li><ul><li>the S3 and EC2 Amazon machine image will cost, due to the hourly usage of storage and compute</li></ul></li>
</ul>

<p><b>Step One</b></p>

<ul>
<li><p>Log into the <a href="https://console.aws.amazon.com/?nc1=h_m_mc">AWS EC2 Dashboard</a></p></li>
<li><p>Select "Launch Instance"</p></li>
</ul>

<p><b>Step Two</b></p>

<ul>
<li><p>Select AWS Marketplace</p></li>
<li><p>Search "river-ami"</p></li>
<li><p>Select the returned AMI</p></li>
</ul>

<p><b>Step Three</b></p>

<ul>
<li><p>Select Configure Instance Details</p></li>
<li><p>Scroll down and expand "Advanced Details"</p></li>
<li><p>Copy / paste the following into the text box*</p>

<ul><li><p><code>#!/bin/bash</p></li>
<li><p>echo ## Exporting variables for River4 >> /home/river/.bashrc</p></li>
<li><p>echo export AWS_ACCESS_KEY_ID=<YOUR_ACCESS_KEY> >> /home/river/.bashrc</p></li>
<li><p>echo export AWS_SECRET_ACCESS_KEY=<YOUR_SECRET_KEY> >> /home/river/.bashrc</p></li>
<li><p>echo export s3path=/<YOUR_RIVER_ADDRESS>/ >> /home/river/.bashrc</p></li>
<li><p>source /home/river/.bashrc</p></li>
<li><p>su -c "forever start /home/river/river4/river4.js" -s /bin/sh river</code></p></li></ul></li>
<li><p>Ensure that you enter your AWS_ACCESS_KEY, AWS_SECRET_KEY and RIVER_ADDRESS are entered before continuing</p></li>
<li><p>Select Review and Launch</p></li>
<li></li>
<li><ul><li>This script will launch <b>once </b>when the River instance is first instantiated</li></ul></li>
</ul>

<p><b>Step Four</b></p>

<ul>
<li><p>Select Edit Security Groups (optional step*)</p></li>
<li><p>Under Security group name enter</p>

<ul><li><code>SSH Access</code></li></ul></li>
<li><p>Under Description enter</p>

<ul><li><code>SSH Access from known IP address</code></li></ul></li>
<li><p>Under the Source drop down, select My IP</p>

<ul><li>This will select your current IP address as the only address that can access this River instance via SSH</li></ul></li>
<li></li>
<li><ul><li>If you don't mind your River instance allowing SSH access from <i>any</i> IP address on the internet just select Launch at this stage. Else you can tie down which IP address <i>can</i> get SSH access. </li></ul></li>
</ul>

<p><b>Step Five</b></p>

<ul>
<li>Select Launch</li>
</ul>

<p><b>Step Six</b></p>

<ul>
<li><p>Select or create a new key pair</p>

<ul><li>The key pair is needed for when you wish to SSH to the River instance</li></ul></li>
<li><p>To create a new key pair, select Create a new key pair</p></li>
<li><p>Give the key pair a name i.e., <code>ec2-key-pair</code></p></li>
<li><p>Select Download Key Pair and keep the file safe, you will need this should you ever want to SSH to the River instance</p></li>
<li><p>Select Launch Instances</p></li>
</ul>

<p><b>Step Seven</b></p>

<ul>
<li><p>Select View Instances</p>

<ul><li>Within a few seconds the River instance will have spun up and be ready to produce Rivers of news*</li></ul></li>
<li></li>
<li><ul><li>For Rivers of news to be produced you must drop opml file(s) into your River S3 bucket within the /lists subdirectory.</li></ul></li>
<li><p><img src="https://dl.dropbox.com/s/jqwvvfk8vk8spjn/Lists.png?dl=0" &lt;="" img=""></p></li>
<li><p>You can find a set of opml files <a href="https://dl.dropboxusercontent.com/u/36518280/outlines/subscriptionLists.zip">here</a> to get you started. Just upload the extracted opml files to your S3 bucket /lists folder.</p></li>
</ul>

<p><b>Step Eight</b></p>

<ul>
<li><p>Visit your River web address</p>

<ul><li>http://rivers.mydomain.co.uk</li></ul></li>
</ul>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">09/24/14; 07:00:32 PM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="deployingARiverAMIFromEc2.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="howtofargoselfpublishingstorageoptions.html">How-To: Fargo Self-Hosted Publishing - Hosting Fargo blog content</a></div>
		<p><a href="https://twitter.com/share?text=How-To%3A%20Fargo%20Self-Hosted%20Publishing%20-%20Storage%20Alternatives&amp;url=http://scriven.chrisdadswell.co.uk/articles/howto" target="_blank">Tweet This Post</a></p>

<p><img style="float: right; margin-left: 25px; margin-top: 15px; margin-right: 15px; margin-bottom: 15px;" src="https://www.corephp.com/components/com_wordpress/wp/wp-content/uploads/2014/06/vps-hosting.png"></p>

<p><b>Introduction</b></p>

<ul>
<li><p>Over the last weekend I was trying to work out what alternatives I had to storing this stream blog somewhere other than S3. Up until Sunday, this blog had been residing on an Amazon S3 bucket but this storage was actually starting to cost me money so I decided to find a way to store it on my existing <a href="http://en.wikipedia.org/wiki/Virtual_private_server">VPS</a> (virtual private server). In this instance the same VPS that is running my fargoPublisher. See this <a href="http://scriven.chrisdadswell.co.uk/articles/howToSelfPublishingFargoBlog.html">how-to article</a> on how to set that up.</p></li>
<li><p>I started the journey by looking at an article that Dave wrote on <a href="http://fargo.io/docs/contentManagement/usingGithub.html">hosting your site on GitHub Pages</a>. This only took a few minutes to configure as I already had a GitHub page set-up. I played around for a bit but soon got fed up having to commit and sync all the time. There had to be a more seamless solution with minimal effort required. Don't get me wrong, this is a great way to store your pages away from a paid solution such as Amazon S3 but personally it didn't cut it for me. For those wanting to try this solution you can also <a href="https://help.github.com/articles/setting-up-a-custom-domain-with-github-pages">setup a custom domain for your GitHub pages</a>.</p></li>
<li><p>So call me a control freak, I wanted total control of where my site was stored.</p></li>
<li><p>If you notice, part of the config for using GitHub Pages as storage there is that there is a directive called "<i>#siteFolder</i>". This "<i>tells Fargo where to store your files.</i>" - This was all I needed!</p></li>
<li><p>You see, when you use this directive in your blog it essentially renders the site to the root of the "Dropbox/Apps/Fargo" folder within your Dropbox account. For example, my #siteFolder directive is <code>#siteFolder "blogs/scriven/"</code></p></li>
<li><p>When I render my site it renders the output to /Dropbox/Apps/Fargo/blogs/scriven </p></li>
<li><p>Fantastic, so now I can render my site locally to Dropbox. But how to get this content across to my VPS seamlessly? Read the rest of this how-to to find out! :hand-o-down:</p></li>
</ul>

<p><b>TLDR Overview</b></p>

<ul>
<li><p>Setup the Fargo blog to render content to your Dropbox account</p></li>
<li><p>Synchronise the site from Dropbox to your VPS using <a href="http://www.dropboxwiki.com/tips-and-tricks/install-dropbox-in-an-entirely-text-based-linux-environment">dropboxd</a></p></li>
<li><p>Configure Apache to make the site(s) available</p></li>
<li><p>Create a cronjob on the VPS to sync the contents of the Dropbox site content to your Apache content folders </p></li>
<li><p>Update your DNS records</p></li>
<li><p>Enjoy your totally self published Fargo blog</p></li>
</ul>

<p><b>Configuring your site to render to Dropbox</b></p>

<ul>
<li><p>This step is very straight-forward.</p></li>
<li><p>Open your outline into Fargo</p></li>
<li><p>At the bottom of the outline add; Of course you can call your blog what you would like. I'm calling this example, battyblog</p>

<ul><li><code>#siteFolder "blogs/battyblog"</code></li></ul></li>
<li><p>NOTE: The reason I added "blogs/" is because I have more than one blog that I publish out of Fargo.</p>

<ul><li><p>blogs/scriven - stream blog</p></li>
<li><p>blogs/copula - link blog</p></li></ul></li>
<li><p>With this folder structure you can have any number of blogs under the "blogs" subdirectory. Of course you can choose any folder you wish. This made made the most sense for my requirements.</p></li>
<li><p>Once you have some content to render go to the "File" menu and select "Render All Pages"</p></li>
<li><p>In a few seconds the publisher will create the necessary file structure and the content beneath it. You can check this by going to your Dropbox account and looking under;</p>

<ul><li>Apps/Fargo/blogs/<outline name></li></ul></li>
<li><p>As if by magic, under blogs you will see your outline name. Within that will be the content of your blog.</p></li>
<li><p>The next step is to synchronize your blog content with the VPS, but this requires that the VPS has the Dropbox sync daemon installed and configured. We will tackle this in the next section.</p></li>
</ul>

<p><b>Installing and configuring VPS prerequisites</b></p>

<ul>
<li><p>This section is a little more involved, but I will lead you through as coherently as I can.</p></li>
<li><p>For the following set of instructions I have been using a Debian 7 VM. Other Linux flavours may vary.</p></li>
<li><p>Whatever distro you use, you will need the following;</p>

<ul><li><p>wget</p></li>
<li><p>Python 2.x (3.x not currently supported)</p></li>
<li><p>a web browser*</p></li></ul></li>
<li><p>*The web browser can be the one on your machine</p></li>
<li><p>So lets get going by connecting to the VPS via a root SSH session</p></li>
<li><p>Once logged in run the following to get the dropboxd software pre-reqs installed. It might be that you already have Python installed on the server.</p>

<ul><li><code>apt-get install wget python</code></li></ul></li>
<li><p>Once they are installed let's create a standard user for the purpose of running dropboxd and other Dropbox cli commands later on in this guide</p></li>
<li><p>In this example I will create a user called "<i>batty</i>"</p>

<ul><li><p><code>useradd -G sudo -d /home/batty -m -s /bin/bash batty</code></p></li>
<li><p><code>passwd batty</code></p></li>
<li><p><code>chown -R batty:sudo /home/batty</code></p></li>
<li><p><code>usermod -G sudo batty</code></p></li></ul></li>
<li><p>Switch user to batty and change to the home directory</p>

<ul><li><p><code>su - batty</code></p></li>
<li><p><code>cd ~</code></p></li></ul></li>
</ul>

<p><b>Downloading, installing and using the Dropbox CLI via dropbox.py</b></p>

<ul>
<li><p>The steps carried out here enabled us to control the dropbox daemon, dropboxd. This step is useful before getting the dropbox daemon because once we download and run dropboxd it will start to download all your files! With the use of the dropbox CLI, dropbox.py, we can control dropboxd. <img title=':wink:' alt=':wink:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/wink.png' align='absmiddle' /> .. You'll thank me for this step I can assure you!</p></li>
<li><p>So lets go get the Dropbox CLI</p>

<ul><li><code>wget -O ~/bin/dropbox.py "https://www.dropbox.com/download?dl=packages/dropbox.py"</code> </li></ul></li>
<li><p>Modify the file to allow execution</p>

<ul><li><code>chmod +x ~/dropbox.py</code> </li></ul></li>
<li><p>View the help associated with the Dropbox CLI, this will give you an idea of what commands are possible. We will using a few of them shortly.</p>

<ul><li><code>python ~/dropbox.py help</code> </li></ul></li>
<li><p>But before that, we need to download the Dropbox daemon</p></li>
</ul>

<p><b>Downloading the Dropbox daemon, dropboxd</b></p>

<ul>
<li><p>Download the dropbox daemon, dropboxd. In this guide we will be using the 64bit version</p>

<ul><li><p><code>wget -O dropbox.tar.gz "http://www.dropbox.com/download/?plat=lnx.x86_64"</code></p></li>
<li><p><code>tar -xvzf dropbox.tar.gz</code> </p></li></ul></li>
<li><p>This creates a hidden directory <code>~/.dropbo<img title=':stuck_out_tongue_closed_eyes:' alt=':stuck_out_tongue_closed_eyes:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/stuck_out_tongue_closed_eyes.png' align='absmiddle' />ist</code> with an executable called <code>dropboxd</code></p></li>
<li><p>We will now run dropboxd and link it with you Dropbox account</p></li>
<li><p>To run dropboxd, type the following;</p>

<ul><li><code>~/.dropbo<img title=':stuck_out_tongue_closed_eyes:' alt=':stuck_out_tongue_closed_eyes:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/stuck_out_tongue_closed_eyes.png' align='absmiddle' />ist/dropboxd</code></li></ul></li>
<li><p>You will then see the following output;</p>

<ul><li><code>This client is not linked to any account... Please visit <b>https://www.dropbox.com/cli_link?host_id=<big_long_guid></b> to link this machine.</code> </li></ul></li>
<li><p>Copy the url and paste into a browser.  After a few ticks you will see a message telling you that the computer is now linked with your Dropbox account </p></li>
<li><p>Back at the SSH session you will see that the dropboxd has now connected with your Dropbox account.</p></li>
<li><p>The result of this is a new directory in the root of the home directory;</p>

<ul><li><code>Dropbox</code></li></ul></li>
<li><p>The Dropbox daemon will now be downloading all of your Dropbox folders and files, so we need to stop it.</p>

<ul><li><code>python dropbox.py stop</code></li></ul></li>
<li><p>Running the following command will show the status of the Dropbox daemon at any given time</p>

<ul><li><code>python dropbox.py status</code></li></ul></li>
<li><p>It should now be stopped;</p>

<ul><li><code>Dropbox daemon stopped</code></li></ul></li>
<li><p>Because we only want to synchronise our "Dropbox/Apps/Fargo/blogs" folder, we may need to do some Dropbox folder exclusions. In the case of my personal setup I had to exclude a good number of folders. Below shows an example of how to perform an exclusion; </p>

<ul><li><code>python dropbox.py exclude add Dropbox/<folder_name></code></li></ul></li>
<li><p>To add multiple exclusions in one hit;</p>

<ul><li><code>python dropbox.py exclude add Dropbox/<folder_name> Dropbox/<folder_name></code></li></ul></li>
<li><p>If you need to list folders within your Dropbox;</p>

<ul><li><code>python dropbox.py list</code></li></ul></li>
<li><p>One last thing before you setup your exclusions, you need to start the Dropbox daemon;</p>

<ul><li><code>python dropbox.py start</code></li></ul></li>
<li><p>Now go setup your exclusions! When you're done, come back here and we'll carry on... Are you done yet? ... OK let's get on with it. </p></li>
<li><p>OK, so now we have only the Dropbox/Apps/Fargo/blogs folder in sync with Dropbox</p></li>
<li><p>You can have a look in the folder by typing;</p>

<ul><li><code>ls ~/Dropbox/Apps/Fargo/blogs</code></li></ul></li>
<li><p>Finally, let's make sure that dropboxd starts at every boot;</p>

<ul><li><code>python dropbox.py autostart</code></li></ul></li>
<li></li>
<li><p>In the next section we will configure an Apache site to run the blog from.  </p></li>
</ul>

<p><b>Installing and configuring Apache to run your blog</b></p>

<ul>
<li><p>First off we need to install Apache, if you haven't already got it installed;</p>

<ul><li><code>sudo apt-get install apache2</code></li></ul></li>
<li><p>With Apache installed, we need to create a directory to store the blog content, in this example, my blog is called "battyblog"</p>

<ul><li><code>sudo mkdir -p /var/www/battyblog</code></li></ul></li>
<li><p>Alter the ownership of this folder to allow our "batty" user to create/delete files/folders</p>

<ul><li><code>sudo chown -R batty:www-data /var/www/battyblog</code></li></ul></li>
<li><p>Next we will configure the sites-available to Apache and add configuration for the battyblog site</p></li>
<li><p>Let's go to the Apache "sites-available" directory</p>

<ul><li><code>cd /etc/apache2/sites-available</code></li></ul></li>
<li><p>Create a new file with the name being that of your blog</p>

<ul><li><code>sudo nano battyblog</code></li></ul></li>
<li><p>Copy and paste the following into the new file, obviously replacing the domain name with yours</p>

<ul><li><p><code>&#060;VirtualHost *:80&#062;</code></p></li>
<li><p><code>ServerName battyblog.domain.co.uk</code></p></li>
<li><p><code>DocumentRoot /var/www/battyblog</code></p></li>
<li><p><code>ErrorLog ${APACHE_LOG_DIR}/battyblog_error.log</code></p></li>
<li><p><code>CustomLog ${APACHE_LOG_DIR}/battyblog_access.log combined</code></p></li>
<li><p><code>&#060;/VirtualHost&#062;</code></p></li></ul></li>
<li><p>Now we can enable the battyblog site to make it available</p>

<ul><li><p><code>sudo a2ensite battyblog</code> </p></li>
<li><p><code>sudo service apache2 restart</code></p></li></ul></li>
<li><p>If all went to plan, the site should now be available</p></li>
<li><p>Next stage is to put our Dropbox synchronised blog content into our Apache site, battyblog. </p></li>
<li></li>
<li><p><b>NOTE:</b> I haven't covered any aspects of <a href="http://httpd.apache.org/docs/current/misc/security_tips.html">Apache security</a> that can be configured. That is out of the scope of this article! But I suggest you go do some reading on the subject prior to going live. </p></li>
</ul>

<p><b>Syncing the local blog with your Apache content directory </b></p>

<ul>
<li><p>Time to take some stock and see where we are.</p></li>
<li><p>The root of the battyblog site from a local Dropbox perspective is;</p>

<ul><li><p>Dropbox blog location</p></li>
<li><p><code>~/Dropbox/Apps/Fargo/blogs/battyblog</code></p></li></ul></li>
<li><p>The root Web directory of the blog has been set to;</p>

<ul><li><p>Apache blog location</p></li>
<li><p><code>/var/www/battyblog</code></p></li></ul></li>
<li><p>Next we need to setup a simple <i>one-way</i> rsync job to synchronise the content from our local Dropbox location to the root of the Apache blog location.</p>

<ul><li>~/Dropbox/Apps/Fargo/blogs -> /var/www/battyblog</li></ul></li>
<li><p>Open up the crontab</p>

<ul><li><code>crontab -e</code></li></ul></li>
<li><p>Copy and paste the following into a blank line of the crontab</p>

<ul><li><p><code>* * * * * /usr/bin/rsync -avzh --delete /home/scriven/Dropbox/Apps/Fargo/blogs/ /var/www/ &#060; /dev/null 2>&amp;1</code> </p></li>
<li><p><code>CTRL o</code></p></li>
<li><p><code>CTRL x</code></p></li></ul></li>
<li><p>This will run an rsync (with delete) every minute. The delete will remove files on the destination directory at every sync. The <code>&#060; /dev/null&#060;&amp;1</code> ensures that your batty mailbox doesn't get filled up with run messages! You're welcome <img title=':smiley:' alt=':smiley:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/smiley.png' align='absmiddle' /> </p></li>
<li><p>With that final step you should see the content of the blog start to appear in a few moments in the <code>/var/www/battyblog</code> directory.</p></li>
<li><p>In the next section we will finish off by configuring the DNS for your domain so that the blog appears on the internet.</p></li>
</ul>

<p><b>Configure DNS to allow visits to the self-hosted blog</b></p>

<ul>
<li><p>Go to your DNS management and create a new 'A' record that points to the IP address of the VPS we have just been working on.</p></li>
<li><p>For example; <code>A battyblog.mydomain.co.uk 123.123.123.123</code></p></li>
<li><p>NOTE: This change may take minutes, possibly hours.</p></li>
<li><p>Once the change has occurred visit the site to see the fruits of your labour</p>

<ul><li>http://battyblog.mydomain.co.uk</li></ul></li>
<li><p>Any changes you now make to your blog will be synchronised within a minute or two with your VPS.</p></li>
<li><p>And this is where this article comes to an end, if you have any questions or comments please contact me <a href="twitter.com/chrisdadswell">@chrisdadswell</a> on Twitter.</p></li>
</ul>

<p><b>VPS provider</b></p>

<ul>
<li><a href="http://cloudatcost.com">Cloud at Cost</a> - One off payment of $35 or $1 a month</li>
</ul>

<p><b>Links used for this guide</b></p>

<ul>
<li><p><a href="http://fargo.io/docs/contentManagement/usingGithub.html">Using GitHub to host your site content</a></p></li>
<li><p><a href="http://www.dropboxwiki.com/tips-and-tricks/install-dropbox-in-an-entirely-text-based-linux-environment">Installing Dropbox in a text based Linux environment</a></p></li>
<li><p><a href="http://www.dropboxwiki.com/tips-and-tricks/using-the-official-dropbox-command-line-interface-cli">Using the Dropbox CLI</a></p></li>
<li><p><a href="http://httpd.apache.org/docs/current/misc/security_tips.html">13 Tips for securing Apache</a></p></li>
</ul>

<p><b>Credits</b></p>

<ul>
<li>Dave Winer - Creator of Fargo and other such software snacks(tm) :cheesecake:</li>
</ul>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">07/14/14; 03:44:41 PM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="howtofargoselfpublishingstorageoptions.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="howToSelfPublishingFargoBlog.html">How-To: Fargo Self-Hosted Publishing - Hosting the fargoPublisher</a></div>
		<p><a href="https://twitter.com/share?text=How-To%3A%20Fargo%20Self-Hosted%20Publishing&amp;url=http://scriven.chrisdadswell.co.uk/users/scriven/2014/06/19/fargoSelfPublishingPart2" target="_blank">Tweet This Post</a></p>

<p><b>Introduction</b></p>

<ul>
<li><p>This post is being written on my self hosted Fargo published site. It has taken  me some time to work out how this is done and I'd like to give back to the community by showing you how I managed it. It's not all there yet, but for the most part it works and it has been a very interesting journey. </p></li>
<li><p>I've been following Fargo for about a year now and have found it an extremely captivating way to edit and post content. I've used all the popular "blogging platforms" out there, although I freely admit I don't post up content as much as I'd like. I've also been following Dave Winer for longer than this and find him a very inspiring character to learn a great deal from. I also like that he is very attentive to those that follow him on the <a href="http://fargo.io/docs/support.html">groups </a>and nearly always responds. Not too shabby!</p></li>
<li><p>I've been ingesting RSS for longer than I can remember and it was only really a year or so ago, when Google Reader disappeared, that I took an active interest in what RSS was really about and what can be achieved with it and where it is going.</p></li>
<li><p>I love the Fargo platform and it's been a joy to watch it progress and finally get it working on a self hosted platform. As Dave has so kindly allowed it to be used. </p></li>
<li><p>I've read a lot of material to get to this point and I'm also quite fortunate that my day job and experience has helped a great deal in the process. But I hope the following will help all those wanting to achieve the same aim of self hosting a Fargo blog.</p></li>
<li><p>"Enough of this" I hear you say, let us move onto the good stuff. <img title=':bomb:' alt=':bomb:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/bomb.png' align='absmiddle' /></p></li>
</ul>

<p><b>fargoPublisher and fargoPublisherSetup on GitHub</b></p>

<ul>
<li><p><b><a href="https://github.com/scripting/fargoPublisher">fargoPublisher on GitHub</a></b></p></li>
<li><p><b><a href="https://github.com/chrisdadswell/fargoPublisherSetup">fargoPublisherSetup on Github</a></b> <em>updated 2014/09/01</em></p>

<ul>-</ul></li>
</ul>

<p><b>Technical Overview</b></p>

<ul>
<li><img src="https://dl.dropbox.com/s/fchscw6zgloty5m/Fargo%20Architecture.png"></li>
</ul>

<p><b>Setting up AWS</b></p>

<ul>
<li><p>It goes without saying that you need an <a href="http://aws.amazon.com/">Amazon AWS account</a> (free for 12 months)</p></li>
<li><p>Log into the AWS console and create a <a href="https://console.aws.amazon.com/iam/home?region=eu-west-1#users">new user</a></p></li>
<li><p>As part of the creation of a new user you will be able to get the Access Key ID and Secret Access Key these are needed for the fargoPublisher later on so please keep a note of them</p></li>
<li><p>Create an S3 bucket (US Default) to hold the static files that the Fargo publisher will produce. I called mine "<i>scriven.chrisdadswell.co.uk</i>"</p></li>
<li><p>You now need to enable "<i>website hosting</i>" for this bucket</p>

<ul><li><p>Click on the bucket and select the "Properties" button on the top right. </p></li>
<li><p>Click the radio button to enable website hosting</p></li>
<li><p>Enter "<i>Index.html</i>" in the Index Document field</p></li>
<li><p>Save</p></li>
<li><p>Make a note of the "endpoint" url above or copy to notepad. This will also be needed later</p></li></ul></li>
<li><p>Finally, set-up a bucket policy. This is needed for access write access to the bucket.</p>

<ul><li>Read the "Granting Read-Only Permission to an Anonymous User" section on this <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html">here</a> </li></ul></li>
<li><p>AWS setup is now complete</p></li>
</ul>

<p><b>Setting up DNS (CloudFlare)</b></p>

<ul>
<li><p>My DNS is managed at CloudFlare, I have a free account. Your DNS management may vary.</p></li>
<li><p>Create an "A" record for the fargoPublisher host, I called my "A" record "pub" and entered the public IP address to the host. It has to be an IP address for this type of record.</p></li>
<li><p>Next, create a  "CNAME" record that points to the S3 bucket URI. I called my "scriven". This bucket that holds all the Fargo user and stats data. This DNS record points to the S3 bucket endpoint we recorded above in the AWS console.</p></li>
</ul>

<p><b>Setting up the Linux server</b></p>

<ul>
<li><p>I am running fargoPublisher on a Debian 7 VM that I purchased outright from CloudAtCost.com for $38 and comes with a fixed IP <img title=':smiley:' alt=':smiley:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/smiley.png' align='absmiddle' /></p></li>
<li><p>Login into your system as the root user</p></li>
<li><p>Prerequisite software to install as root:</p>

<ul><li><code>apt-get install sudo git curl</code></li></ul></li>
<li><p>Create a new user for Fargo (optional username). I'm using "<i>fargo</i>"</p>

<ul><li><p><code>useradd -G sudo -d /home/fargo -m -s /bin/bash fargo</code></p></li>
<li><p><code>passwd fargo</code></p></li>
<li><p><code>chown -R fargo:user /home/fargo</code></p></li>
<li><p><code>usermod -G sudo fargo</code></p></li></ul></li>
<li><p><a href="https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager">Build</a> Node.js from source (Source: Joyent on GitHub) - The build process takes a little while. Why not go grab a drinky and a bit to eat <img title=':cake:' alt=':cake:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/cake.png' align='absmiddle' /></p>

<ul><li><p><code>apt-get install python g++ make checkinstall fakeroot</code></p></li>
<li><p><code>src=$(mktemp -d) &amp;&amp; cd $src</code></p></li>
<li><p><code>wget -N http://nodejs.org/dist/node-latest.tar.gz</code></p></li>
<li><p><code>tar xzvf node-latest.tar.gz &amp;&amp; cd node-v*</code></p></li>
<li><p><code>./configure</code></p></li>
<li><p><code>fakeroot checkinstall -y --install=no --pkgversion $(echo $(pwd) | sed -n -re's/.+node-v(.+)$/\1/p') make -j$(($(nproc)+1)) install</code></p></li>
<li><p><code>sudo dpkg -i node_*</code> </p></li></ul></li>
<li><p>Install <b>N</b>ode <b>P</b>ackage <b>M</b>anager or npm</p>

<ul><li><code>curl https://www.npmjs.org/install.sh | sudo sh</code></li></ul></li>
<li><p>Test node is installed by returning a version</p>

<ul><li><code>node -v</code></li></ul></li>
<li><p>Switch to the fargo user to install the required npm modules</p>

<ul><li><code>su - fargo</code></li></ul></li>
<li><p>Install fargoPublisher node pre-requisites</p>

<ul><li><p><code>sudo npm install aws-sdk url request</p></li>
<li><p>sudo npm install forever -g</code></p></li></ul></li>
</ul>

<p><b>Install and configure fargoPublisher</b></p>

<ul>
<li><p>Read the <a href="https://github.com/scripting/fargoPublisher/blob/master/README.md">fargoPublisher README</a></p></li>
<li><p>Clone the fargoPublisher into the fargo users home directory</p>

<ul><li><code>git clone https://github.com/scripting/fargoPublisher.git</code></li></ul></li>
<li><p>Subsequent updates can be retrieved by running the following from within the fargoPublisher directory</p>

<ul><li><code>git pull origin</code></li></ul></li>
<li><p>We will now set-up the required export variables. I did this in my fargo users <code><i>.profile</i></code> file so that the variables get exported when the fargo user logs onto the system. The <code>.profile</code> file is a hidden file within the fargo users home directory</p>

<ul><li><p><code>cd ~</code></p></li>
<li><p><code>sudo nano .profile</code></p></li></ul></li>
<li><p>NOTE: My server also runs other web services, so I have chosen not to run it on the standard port of 80, but on 8080 as you will see later. </p></li>
<li><p>Paste the following and change with your values for AWS keys, domain names and port</p>

<ul><li><p><code>## AWS IAM fargo user keys</code></p></li>
<li><p><code>export AWS_ACCESS_KEY_ID=<ACCESS KEY ID></code></p></li>
<li><p><code>export AWS_SECRET_ACCESS_KEY=<SECRET ACCESS KEY></code></p></li>
<li><p><code>## Exporting variables for fargoPublisher</code> </p></li>
<li><p><code>export fpHostingPath=/scriven.chrisdadswell.co.uk/users/</code></p></li>
<li><p><code>export fpDataPath=/scriven.chrisdadswell.co.uk/data/</code></p></li>
<li><p><code>export fpDomain=chrisdadswell.co.uk</code></p></li>
<li><p><code>export fpServerPort=8080</code></p></li>
<li><p><code>export fpRedirect=false</code></p></li></ul></li>
<li><p>CTRL O and CTRL X to save and quit</p></li>
<li><p>Source the <code>.profile</code> to export the variables. This essentially runs the <code>.profile</code> as if we'd logged in</p>

<ul><li><code>source .profile</code></li></ul></li>
<li><p>Test the fargoPublisher runs and watch the output. When the fargoPublisher is running you will see the variables that were exported on screen and it will appear to be doing nothing.</p>

<ul><li><code>cd fargoPublisher &amp;&amp; node publisher.js</code></li></ul></li>
<li><p>This should return by showing the variables set and sit stationary without a prompt in the running state</p></li>
<li><p>Keep the SSH session open for now.</p></li>
<li><p>Fire up a browser and test that the publisher is responding. Obviously change the domain and port below to that of the one you have set-up.</p>

<ul><li><code>http://<publisher url>:8080/version</code></li></ul></li>
<li><p>This should return "0.96" in the body of the page. This proves the publisher is responding and ready to go. <img title=':thumbsup:' alt=':thumbsup:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/thumbsup.png' align='absmiddle' /></p></li>
</ul>

<p><b>Testing fargoPublisher</b></p>

<ul>
<li><p>Head over to <a href="http://fargo.io">Fargo.io</a> in your browser. As mentioned above I found it useful at this stage to keep the SSH session open to your Debian server that is currently running the fargoPublisher. </p></li>
<li><p>NOTE: We will run the publisher in the background using "forever" once testing is complete.</p></li>
<li><p>Create  a new outline and name it "testing1" for the sake of this test. You can delete it from Dropbox once we are done testing</p></li>
<li><p>Click the "+" icon on the left and make an entry</p></li>
<li><p>Next we will change the CMS publisher server address</p></li>
<li><p>Go to the Fargo "Settings..." This can be found by clicking your name on the far right of the title bar in Fargo.</p></li>
<li><p>Click the CMS tab and enter the publisher server details. Change the domain and port to match your details. </p>

<ul><li><code>http://pub.chrisdadswell.co.uk:8080</code></li></ul></li>
<li><p>This is to tell Fargo that <i>your</i> publisher will be publishing files and not the default publisher over at "pub.fargo.io"</p></li>
<li><p>Give that a few ticks to save off and update in the background before continuing</p></li>
<li><p>Next we will publically name the outline, this is the point where will see if the publisher and everything else we have setup is working!</p></li>
<li><p>Make the SSH session visible that is running the publisher. It will show debug information as we start to type an outline name. </p></li>
<li><p>Make sure the "<i>testing1</i>" outline is selected then</p>

<ul><li>File | Name outline...</li></ul></li>
<li><p>Enter "<i>testing1</i>" - Note that you will see the publisher updating as you enter each letter. If you don't see any output it would suggest something isn't quite working <img title=':thumbsdown:' alt=':thumbsdown:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/thumbsdown.png' align='absmiddle' /></p></li>
<li><p>Press OK to confirm the public outline name. If all went well Fargo will report that the public outline naming has been successful.</p></li>
<li><p>Now we want to render the pages.</p>

<ul><li>File | Render All Pages...</li></ul></li>
<li><p>Give Fargo a few seconds to render the pages into the bucket. :lightbulb: Tip: If you are doing all this from a PC and have Dropbox installed with notifications set, you will see when Fargo is publishing.</p></li>
<li><p>We are now at a point where we have a public outline that has been published by your fargoPublisher and its static content rendered to your S3 bucket. :child: :hi5: :child:</p></li>
<li><p>As you would of read above, fargoPublisher has a concept of users. These are in actual effect the names of the outlines you create. If you log into your S3 account and look at the bucket you are using you will see "<i>data</i>" and "<i>users</i>" folders. </p></li>
<li><p>Inside the "<i>users</i>" folder you will see a "<i>testing1</i>" user with the static contents that the fargoPublisher rendered. Neat hey.</p></li>
<li><p>To get access to the pages in your browser go to http://yourdomain/users/testing1</p></li>
<li><p>And there you have it, a self published and static hosted blog!</p></li>
 - 
</ul>

<p><b>Backgrounding the fargoPublisher</b> </p>

<ul>
<li><p>Up to this point we have been running the fargoPublisher in the foreground. This means terminating the process or logging off will terminate the fargoPublisher.</p></li>
<li><p>To address this we can run the publisher in the background using an npm module called "<i>forever</i>". This essentially runs the node as a service that is controllable and creates logs.</p></li>
<li><p>To do this is very straight-forward as I will show below. First we need to terminate the fargoPublisher</p>

<ul><li><code>CTRL c</code></li></ul></li>
<li><p>From within the fargoPublisher directory, run the following command</p>

<ul><li><code>forever start publisher.js</code></li></ul></li>
<li><p>This will start the publisher and you will see some output and be returned to the command line. At this point fargoPublisher is running in the background.</p></li>
<li><p>If at any point you want to stop the publisher, do the following</p>

<ul><li><code>forever stopall</code></li></ul></li>
<li><p>or</p>

<ul><li><code>forever stop publisher.js</code></li></ul></li>
<li><p>In the next section I will demonstrate how to run the fargoPublisher at start-up. This is needed if the server is needing to be rebooted at any time.</p></li>
</ul>

<p><b>Running fargoPublisher at boot</b></p>

<ul>
<li><p>Again, this is a really simple config on the server side. I use the "<i>crontab</i>" to start the fargoPublisher at boot</p>

<ul><li><code>crontab -e</code></li></ul></li>
<li><p>Scroll down to an empty line and paste the following</p>

<ul><li><code>@reboot /usr/local/bin/forever start /usr/local/bin/node /home/fargo/fargoPublisher/publisher.js</code> </li></ul></li>
<li><p>CTRL o then CTRL x (for nano)</p></li>
<li><p>or</p></li>
<li><p>ESC wq <for vi></p></li>
<li><p>Running the following will show the cron job</p>

<ul><li><code>crontab -l</code></li></ul></li>
<li><p>On a system reboot now the fargoPublisher will startup without any intervention required. </p></li>
<li><p>One final thing, to list what node processes you have running with forever, type</p>

<ul><li><code>forever list</code></li></ul></li>
<li><p>Fin!</p></li>
</ul>

<p><b>Removing Fargo Users</b></p>

<ul>
<li>Coming soon ...</li>
</ul>

<p><b>What I haven't been able to work out</b></p>

<ul>
<li><p>I haven't quite worked out what is happening with domains for user accounts (see the "<a href="http://fargo.io/docs/contentManagement/runningYourOwnServer.html">remaining loose-ends</a>"). Dave manages to allow users to go to say "scriven.smallpict.com" and the content is generated. At the moment I have to hard code the entry point to the content under /users/scriven within the "Outline Settings". E.g., http://scriven.chrisdadswell.co.uk/users/scriven.</p></li>
<li><p>Ideally I'd want content to be delivered from http://scriven.chrisdadswell.co.uk</p></li>
</ul>

<p><b>Credits</b></p>

<ul>
<li><p>Dave Winer for giving us Fargo and River and for his endless enthusiasm, insight and RSS!</p></li>
<li><p>Frank McPherson for spotting some missives in my article</p></li>
<li><p>Ben and Cogs.com for his feedback</p></li>
<li><p>The people on the smallpict Google groups</p></li>
</ul>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">06/17/14; 11:56:04 AM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="howToSelfPublishingFargoBlog.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="howToSetupAFargoRiverOfNews.html">How-To: Setting up a River of news</a></div>
		<p><a href="https://twitter.com/share?text=How-To%3A%20Setting%20up%20a%20River%20of%20news&amp;url=http://scriven.chrisdadswell.co.uk/articles/howToSetupAFargoRiverOfNews" target="_blank">Tweet This Post</a></p>

<p><b>Introduction</b></p>

<ul>
<li><p><a href="http://scripting.com/2014/06/02/whatIsARiverOfNewsAggregator.html">What is a River of news (2014)?</a></p></li>
<li><p><a href="http://river2.newsriver.org/">What is a River of news (2011)?</a></p></li>
<li><p>The setup of your own River is pretty similar to the setup for Fargo self-publishing. I will in any case run through the entire setup for the sake of completeness.</p></li>
<li><p>Here is a <a href="http://river.scripting.com/">River of news</a>.</p></li>
</ul>

<p><b>Visit <a href="https://github.com/scripting/river4">River4 on GitHub</a></b></p>

<p><b>Setting up AWS</b></p>

<ul>
<li><p>You need an <a href="http://aws.amazon.com/">Amazon AWS account</a> (free for 12 months)</p></li>
<li><p>Log into the AWS console and create a <a href="https://console.aws.amazon.com/iam/home?region=eu-west-1#users">new user</a></p></li>
<li><p>As part of the creation of a new user you will be able to get the Access Key ID and Secret Access Key these are needed for River4 configuration later on so please keep a note of them</p></li>
<li><p>Create an S3 bucket (US Default) to hold the static files that River4 will consume (opml) and produce output (html). I called my S3 bucket "<i>rivers.chrisdadswell.co.uk</i>"</p></li>
<li><p>You now need to enable "<i>website hosting</i>" for this bucket</p>

<ul><li><p>Click on the bucket and select the "Properties" button on the top right. </p></li>
<li><p>Click the radio button to enable website hosting</p></li>
<li><p>Enter "<i>Index.html</i>" in the Index Document field</p></li>
<li><p>Save</p></li>
<li><p>Make a note of the "endpoint" url above or copy to notepad. This will also be needed later</p></li></ul></li>
<li><p>Finally, set-up a bucket policy. This is needed for access write access to the bucket.</p>

<ul><li>Read the "Granting Read-Only Permission to an Anonymous User" section on this <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/example-bucket-policies.html">here</a> </li></ul></li>
<li><p>The S3 bucket setup is now complete</p></li>
</ul>

<p><b>Setting up DNS (CloudFlare)</b></p>

<ul>
<li><p>My DNS is managed bt CloudFlare, I have a free account. Your DNS management may vary.</p></li>
<li><p>Next, create a  "<i>CNAME</i>" record that points to the S3 bucket URI. I called my "rivers".  This DNS record needs to points to the S3 bucket endpoint we recorded above in the AWS console.</p></li>
<li><p>DNS configuration is now complete.</p></li>
</ul>

<p><b>Manual or Automated River4 Setup</b></p>

<ul>
<li><p>The rest of this article explains the steps required to get a River4 application up and running on a Linux server. You can choose to go down the manual setup and configure route or use a script I created over on <a href="https://github.com/chrisdadswell/riverOfNewsSetup/blob/master/README.md">GitHub</a>.</p></li>
<li><p>You will still need to go through the steps of creating an S3 bucket and setup DNS records etc, but the bulk of the manual work involved when setting up the Linux server can be subverted by using the script. The choice is yours!</p></li>
</ul>

<p><b>Setting up the Linux server</b></p>

<ul>
<li><p>I am running River4 on a Debian 7 VM that I purchased outright from CloudAtCost.com for $38 and comes with a fixed IP <img title=':smiley:' alt=':smiley:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/smiley.png' align='absmiddle' /></p>

<ul><li><b>NOTE</b>: This is the same host I am running the fargoPublisher on, so if you intend to run River4 on the same host you can do so without following the install steps below. You can create a separate user if you wish.</li></ul></li>
<li><p>Login into your system as the root user</p></li>
<li><p>Prerequisite software to install as root:</p>

<ul><li><code>apt-get install sudo git curl</code></li></ul></li>
<li><p>Create a new user for River (optional username). I'm using "<i>river</i>"</p>

<ul><li><p><code>useradd -G sudo -d /home/river -m -s /bin/bash river</code></p></li>
<li><p><code>passwd river</code></p></li>
<li><p><code>chown -R river:user /home/river</code></p></li>
<li><p><code>usermod -G sudo river</code></p></li></ul></li>
<li><p><a href="https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager">Build</a> Node.js from source (Source: Joyent on GitHub) - The build process takes a little while. Why not go grab a drinky and a bit to eat <img title=':cake:' alt=':cake:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/cake.png' align='absmiddle' /></p>

<ul><li><p><code>apt-get install python g++ make checkinstall fakeroot</code></p></li>
<li><p><code>src=$(mktemp -d) &amp;&amp; cd $src</code></p></li>
<li><p><code>wget -N http://nodejs.org/dist/node-latest.tar.gz</code></p></li>
<li><p><code>tar xzvf node-latest.tar.gz &amp;&amp; cd node-v*</code></p></li>
<li><p><code>./configure</code></p></li>
<li><p><code>fakeroot checkinstall -y --install=no --pkgversion $(echo $(pwd) | sed -n -re's/.+node-v(.+)$/\1/p') make -j$(($(nproc)+1)) install</code></p></li></ul></li>
<li><p>Install <b>N</b>ode <b>P</b>ackage <b>M</b>anager or npm</p>

<ul><li><code>curl https://www.npmjs.org/install.sh | sudo sh</code></li></ul></li>
<li><p>Test node is installed by returning a version</p>

<ul><li><code>node -v</code></li></ul></li>
<li><p>Switch to the user you are using to run River4 to install the required npm modules</p>

<ul><li><code>su - (user)</code></li></ul></li>
<li><p>Install River4 node pre-requisites</p>

<ul><li><p><code>sudo npm install aws-sdk url request</p></li>
<li><p>sudo npm install forever -g</code></p></li></ul></li>
</ul>

<p><b>Install and configure River4</b></p>

<ul>
<li><p>Read the <a href="https://github.com/scripting/river4/blob/master/README.md">River4 README</a></p></li>
<li><p>Clone the River4 into the users home directory</p>

<ul><li><code>git clone https://github.com/scripting/river4.git</code></li></ul></li>
<li><p>Subsequent updates can be retrieved by running the following from within the /home/river/river4 directory</p>

<ul><li><code>git pull origin</code></li></ul></li>
<li><p>We will now set-up the required export variables. I did this in my river users <code><i>.profile</i></code> file so that the variables get exported when the river user logs onto the system. The <code>.profile</code> file is a hidden file within the river users home directory</p>

<ul><li><p><code>cd ~</code></p></li>
<li><p><code>sudo nano .profile</code></p></li></ul></li>
<li><p>Paste the following and change with your values for AWS keys, domain names and port</p>

<ul><li><p><code>## AWS IAM river user key</code></p></li>
<li><p><code>export AWS_ACCESS_KEY_ID=<ACCESS KEY ID></code></p></li>
<li><p><code>export AWS_SECRET_ACCESS_KEY=<SECRET ACCESS KEY></code></p></li>
<li><p><code>## Exporting variables for River4</code> </p></li>
<li><p><code>export s3path=/rivers.chrisdadswell.co.uk/</code></p></li></ul></li>
<li><p>CTRL O and CTRL X to save and quit</p></li>
<li><p>Source the <code>.profile</code> to export the variables. This essentially runs the <code>.profile</code> as if we'd logged in</p>

<ul><li><code>source .profile</code></li></ul></li>
<li><p>The next step is to put up an OPML file for River4 to process.</p></li>
</ul>

<p><b>Adding feeds to the River</b></p>

<ul>
<li><p>When you look at a River, you have tabs displaying a list of feeds. This list of tabs is generated PER opml file that is dropped onto the S3 storage.</p></li>
<li><p>You place your OPML file(s) into the "<i>lists</i>" sub-folder of your S3 bucket. For example, my bucket is called rivers.chrisdadswell.co.uk so I drop my opml file(s) into the rivers.chrisdadswell.co.uk/lists folder.</p></li>
<li><p>After a few moments the River will begin to flow. Just visit the URL of your River to see it in action. i.e, <a href="http://rivers.chrisdadswell.co.uk">http://rivers.chrisdadswell.co.uk</a>.</p></li>
<li><p>You can also go to <a href="http://rivers.chrisdadswell.co.uk/dashboard">http://rivers.chrisdadswell.co.uk/dashboard</a> to get a view of what is going on.</p></li>
</ul>

<p><b><a href="https://db.tt/1HFkZOeY">Example OPML file</a></b></p>

<p><b>Backgrounding River4</b></p>

<ul>
<li><p>Up to this point we have been running the River4 in the foreground. This means terminating the process or logging off will terminate River4.</p></li>
<li><p>To address this we can run River4 in the background using an npm module called "<i>forever</i>"</p></li>
<li><p>To do this is very straight-forward as I will show below. First we need to terminate the current River4 process</p>

<ul><li><code>CTRL c</code></li></ul></li>
<li><p>From within the /home/users/river directory, run the following command</p>

<ul><li><code>forever start river4.js</code></li></ul></li>
<li><p>This will start River4 and you will see some output and be returned to the command line. At this point River4 is running in the background.</p></li>
<li><p>If at any point you want to stop River4, do the following</p>

<ul><li><code>forever stopall</code></li></ul></li>
<li><p>or</p>

<ul><li><code>forever stop river4.js</code></li></ul></li>
<li><p>In the next section I will demonstrate how to run River4 at start-up. This is needed if the server is needing to be rebooted at any time.</p></li>
</ul>

<p><b>Running River4 at boot</b></p>

<ul>
<li><p>Again, this is a really simple config on the server side. I use the "<i>crontab</i>" to start River4 at boot</p>

<ul><li><code>crontab -e</code></li></ul></li>
<li><p>Scroll down to an empty line and paste the following</p>

<ul><li><code>@reboot /usr/local/bin/forever start /usr/local/bin/node /home/river/river4.js</code> </li></ul></li>
<li><p>CTRL o then CTRL x (for nano)</p></li>
<li><p>or</p></li>
<li><p>ESC wq <for vi></p></li>
<li><p>Running the following will show the cron job</p>

<ul><li><code>crontab -l</code></li></ul></li>
<li><p>On a system reboot now River4 will start-up without any intervention required. </p></li>
<li><p>One final thing, to list what node processes you have running with forever, type</p>

<ul><li><code>forever list</code></li></ul></li>
<li><p>Fin!</p></li>
</ul>

<p><b>Credits</b></p>

<ul>
<li>Dave Winer, the author of River4.js.</li>
</ul>
		</div>
	<div class="divBlogHomeItem">
		<div class="divBlogHomeItemTitle"><a href="fargoScripts.html">Fargo Scripting</a></div>
		<p><b>What are these scripts for?</b></p>

<ul>
<li>These scripts are used to increase productivity and aid some tasks whilst using Fargo.</li>
</ul>

<p><b>How do I use these scripts?</b></p>

<ul>
<li>Watch this <a href="http://www.youtube.com/watch?v=DG9vpDsTv4A">video</a> created by Dave Winer and all will be revealed. Rest assured it's pretty easy.</li>
</ul>

<p><b>Can I import these scripts into a Fargo outline called menubar?</b></p>

<ul>
<li><p>Yes you can! In three easy steps</p></li>
<li><ol><li>Create the "menubar" outline as per the video</li></ol></li>
<li><ol><li>Goto File | Import OPML</li></ol></li>
<li><ol><li><p>Enter this address (my public menubar.opml);</p>

<ul><li><a href="" target="_blank"><a href="https://dl.dropbox.com/s/fsiacjtp7jvx7fk/menubar.opml"><code>https://dl.dropbox.com/s/fsiacjtp7jvx7fk/menubar.opml</code></a></a></li></ul></li></ol></li>
<li><p>Et voila <img title=':thumbsup:' alt=':thumbsup:' class='emoji' src='http://fargo.io/code/emojify/images/emoji/thumbsup.png' align='absmiddle' /></p></li>
</ul>

<p><b>The scripts</b></p>

<ul>
<li>Below are the scripts I have created thus far.</li>
</ul>

<p>Just copy and paste any or all of these script outlines into your #macros.</p>

<p>Add Tweet This Post to Article</p>

<ul>
<li><p><code>var t = op.getLineText ();</p></li>
<li><p>var et = encodeURIComponent(t); </p></li>
<li><p>var link = op.getCursorUrl(); </p></li>
<li><p>twt = "https://twitter.com/share?text=" + et + "&amp;url=" + link;</p></li>
<li><p>op.insert ("Tweet This Post", right);</p></li>
<li><p>op.attributes.setOne ("type", "link");</p></li>
<li><p>op.attributes.setOne ("url", twt);</p></li>
<li><p>op.attributes.setOne ("icon", "twitter-sign");</code></p></li>
</ul>

<p>Send to Outline Viewer</p>

<ul>
<li><p>dialog.confirm ("Send this headline to Small Picture Reader?", function () { </p></li>
<li><p>var path = "snippets/" + string.hashMD5 (clock.now ().toString ()) + ".opml";</p></li>
<li><p>file.writeWholeFile (path, op.getCursorOpml (), function (data) {</p></li>
<li><p>file.getPublicUrl (path, function (url) {</p></li>
<li><p>});</p></li>
<li><p>});</p></li>
</ul>

<p><!-- outlineEmbedCode -- this version gets you a reader -->
	<script src="http://fargo.io/code/concord.js" /></script>
	<script src="http://fargo.io/code/utils.js"></script>
	<style>
		.divTrexEmbeddedOutlineContainer {
			margin-bottom: 20px;
			}
		.divTrexEmbeddedOutlineContainer .divTrexEmbeddedOutliner {
			min-height: 10em;
			max-height: 30em;
			border:1px solid gainsboro;
			border-top-width: 0;
			border-bottom-width: 0;
			overflow-y: auto;
			background-color: white;
			padding: 6px;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divInfoRight {
			float: right;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divOutlineTitle {
			font-weight: bold;
			}
		</style>
	<div class="divTrexEmbeddedOutlineContainer">
		<div id="idAboveOutlineInfo" class="divAboveOutlineInfo">
			<div id="idViewSource" class="divInfoRight"></div>
			<div id="idOutlineTitle" class="divInfoLeft divOutlineTitle"></div>
			</div>
		<div id="idTrexEmbeddedOutliner" class="divTrexEmbeddedOutliner"></div>
		<div id="idBelowOutlineInfo" class="divBelowOutlineInfo">
			<div class="divInfoRight">
				<i class="fa fa-heart" style="color: red; opacity: 0.6; font-size: 0.9em;"></i> 
				<a href="http://fargo.io/" target="_blank">Fargo</a>
				</div>
			<div class="divInfoLeft"></div>
			</div>
		</div>
	<script>
		var font = "Arial", fontSize = 16, lineHeight = 24;
		var opmlUrl = "https://dl.dropboxusercontent.com/s/k5apgnquxhawmte/3d5c0e56735a8d50c73ef6001f5dd84b.opml?dl=0";
		function opKeystrokeCallback () {
			}
		function setPrefs () {
			$("#idTrexEmbeddedOutliner").concord ({
				"prefs": {
					"outlineFont": font, 
					"outlineFontSize": fontSize, 
					"outlineLineHeight": lineHeight,
					"renderMode": true,
					"readonly": true,
					"typeIcons": appTypeIcons
					},
				"callbacks": {
					"opExpand": opExpandCallback,
					"opKeystroke": opKeystrokeCallback
					}
				});
			}
		function getOutline (opmlUrl) {
			var jxhr = $.ajax ({
				url: opmlUrl,
				dataType: "text",
				timeout: 30000
				})
			.success (function (data, status, xhr) {
				if (xhr.status==200) {
					var title;
					$("#idTrexEmbeddedOutliner").concord ().op.xmlToOutline (data, false);
					title = $("#idTrexEmbeddedOutliner").concord ().op.getTitle ();
					$("#idOutlineTitle").html (title);
					$("#idViewSource").html ("<a href='" + opmlUrl + "'>view  source</a>");
					}
				})
			.error (function (status, textStatus, errorThrown) {
				console.log ("checkOutline: error == " + errorThrown + ", status == " + textStatus);
				});
			}
		$(document).ready (function () {
			setPrefs ();
			getOutline (opmlUrl);
			});
		</script></p>

<p>Set Background Image on date of post</p>

<ul>
<li><p>dialog.ask("Enter an image url","http://blah.com/image.jpg","http://blah.com/image.jpg", function(url) {</p></li>
<li><p>op.attributes.setOne ("backgroundImage", url);</p></li>
<li><p>});</p></li>
</ul>

<p><!-- outlineEmbedCode -- this version gets you a reader -->
	<script src="http://fargo.io/code/concord.js" /></script>
	<script src="http://fargo.io/code/utils.js"></script>
	<style>
		.divTrexEmbeddedOutlineContainer {
			margin-bottom: 20px;
			}
		.divTrexEmbeddedOutlineContainer .divTrexEmbeddedOutliner {
			min-height: 10em;
			max-height: 30em;
			border:1px solid gainsboro;
			border-top-width: 0;
			border-bottom-width: 0;
			overflow-y: auto;
			background-color: white;
			padding: 6px;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divInfoRight {
			float: right;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo {
			min-height: 1.5em;
			border:1px solid gainsboro;
			background-color: whitesmoke;
			padding: 4px;
			font-family: "Arial";
			font-size: .9em;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divAboveOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divBelowOutlineInfo a:visited {
			font-family: "Arial";
			font-size: .9em;
			color: #0088cc;
			}
		.divTrexEmbeddedOutlineContainer .divOutlineTitle {
			font-weight: bold;
			}
		</style>
	<div class="divTrexEmbeddedOutlineContainer">
		<div id="idAboveOutlineInfo" class="divAboveOutlineInfo">
			<div id="idViewSource" class="divInfoRight"></div>
			<div id="idOutlineTitle" class="divInfoLeft divOutlineTitle"></div>
			</div>
		<div id="idTrexEmbeddedOutliner" class="divTrexEmbeddedOutliner"></div>
		<div id="idBelowOutlineInfo" class="divBelowOutlineInfo">
			<div class="divInfoRight">
				<i class="fa fa-heart" style="color: red; opacity: 0.6; font-size: 0.9em;"></i> 
				<a href="http://fargo.io/" target="_blank">Fargo</a>
				</div>
			<div class="divInfoLeft"></div>
			</div>
		</div>
	<script>
		var font = "Arial", fontSize = 16, lineHeight = 24;
		var opmlUrl = "https://dl.dropboxusercontent.com/s/tl54c3q808exfom/81bc23b1e5659a3caa1b20967b281ae6.opml?dl=0";
		function opKeystrokeCallback () {
			}
		function setPrefs () {
			$("#idTrexEmbeddedOutliner").concord ({
				"prefs": {
					"outlineFont": font, 
					"outlineFontSize": fontSize, 
					"outlineLineHeight": lineHeight,
					"renderMode": true,
					"readonly": true,
					"typeIcons": appTypeIcons
					},
				"callbacks": {
					"opExpand": opExpandCallback,
					"opKeystroke": opKeystrokeCallback
					}
				});
			}
		function getOutline (opmlUrl) {
			var jxhr = $.ajax ({
				url: opmlUrl,
				dataType: "text",
				timeout: 30000
				})
			.success (function (data, status, xhr) {
				if (xhr.status==200) {
					var title;
					$("#idTrexEmbeddedOutliner").concord ().op.xmlToOutline (data, false);
					title = $("#idTrexEmbeddedOutliner").concord ().op.getTitle ();
					$("#idOutlineTitle").html (title);
					$("#idViewSource").html ("<a href='" + opmlUrl + "'>view  source</a>");
					}
				})
			.error (function (status, textStatus, errorThrown) {
				console.log ("checkOutline: error == " + errorThrown + ", status == " + textStatus);
				});
			}
		$(document).ready (function () {
			setPrefs ();
			getOutline (opmlUrl);
			});
		</script></p>
		<div class="divBlogHomeStoryDate">
			<span class="spFargoStoryDate">07/14/14; 06:33:18 AM</span>
			<div class="divFargoStoryLink" style="float: left;"><a href="fargoScripts.html"><i class="fa fa-star"></i></a></div>
			</div>
		</div>

				<div class="divFooterText">
					<hr>
					<p style="float: right;">Last built: Tue, Jan 13, 2015 at  9:42 PM</p>
					<script>var disqus_identifier = "https://dl.dropbox.com/s/ikd20gpzlebbu6i/articles.opml?dl=0Tue, 13 Jan 2015 21:42:25 GMT";</script><a onclick="showHideComments ()"><span id="idShowHideComments" style="cursor: pointer;"></span></a><div class="divDisqusComments" id="idDisqusComments" style="visibility: visible;" ><div id="disqus_thread"></div></div><script type="text/javascript" src="http://disqus.com/forums/smallpict/embed.js"></script></div>
					<div class="divByline" id="idByline">By <a href="scriven.chrisdadswell.co.uk/about.html" target="_blank">Chris Dadswell</a>, <span id="idWhenCreated">Tuesday, January 13, 2015 at  9:42 PM</span>.</div>
					</div>
				</div>
			</div>
		<script>
			startupFargoPlatform ();
			</script>
		</body>
	</html>
